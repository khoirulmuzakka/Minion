{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"./../\")\n",
    "sys.path.append(\"./../external\")\n",
    "sys.path.append(\"./../external\")\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.optimize import differential_evolution, minimize\n",
    "import matplotlib.pyplot as plt\n",
    "from pyminion import *\n",
    "import concurrent.futures\n",
    "import threading\n",
    "from cec_2011 import * #commmet this line if you do not have matlab installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Problem10()\n",
    "print(p.evaluate(np.random.uniform(p.lb, p.ub)))\n",
    "p.eng.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CEC2011\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function :  1\n",
      "\tObj ARRDE :   4.702488316458331e-28\n",
      "\tObj LSRTDE :   6.279548961349509\n",
      "\tObj NLSHADE RSP :   10.196258280000064\n",
      "Function :  2\n",
      "\tObj ARRDE :   -23.81113218827846\n",
      "\tObj LSRTDE :   -12.277344914710234\n",
      "\tObj NLSHADE RSP :   -21.68974354419291\n",
      "Function :  3\n",
      "\tObj ARRDE :   -0.040486847549302776\n",
      "\tObj LSRTDE :   -0.040487564556161405\n",
      "\tObj NLSHADE RSP :   -0.04047435894679451\n",
      "Function :  4\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "for j in range(5):\n",
    "    for i in range(1, 23):\n",
    "        result = {}\n",
    "        if i ==10 : continue\n",
    "        func = CEC2011(function_number=i, max_workers=8)\n",
    "        bounds = func.getBounds()\n",
    "        dimension = func.dimension\n",
    "        Nmaxeval=50000\n",
    "        if (dimension<10): Nmaxeval=20000\n",
    "        if (i==3 or i==4):  Nmaxeval=200\n",
    "        \n",
    "        result['Dimensions'] = dimension\n",
    "        result['Function_number'] = i\n",
    "        print(\"Function : \", i)\n",
    "        #result =minimize(objective_function, initial_guess, args=(), method='Nelder-Mead', options={\"maxfev\":Nmaxeval, \"adaptive\":True }  ) \n",
    "        #print(\"SIMPLEX done\")\n",
    "        result_arrde = ARRDE(func.evaluate, bounds, data=None,  x0=None, population_size=0, maxevals=Nmaxeval, tol=0.0 ).optimize()\n",
    "        print(\"\\tObj ARRDE :  \", result_arrde.fun)\n",
    "        result_lsrtde = LSRTDE(func.evaluate, bounds, data=None,  x0=None, populationSize=0, maxevals=Nmaxeval ).optimize()\n",
    "        print(\"\\tObj LSRTDE :  \", result_lsrtde.fun)\n",
    "        #result_lshade = LSHADE(objective_function_vect, bounds, data=None,  x0=None, population_size=0, maxevals=Nmaxeval, options= {}).optimize()\n",
    "        #print(\"LSHADE done\")\n",
    "        result_nlshadersp = NLSHADE_RSP (func.evaluate, bounds, data=None, x0=None, population_size=0, \n",
    "                            maxevals=Nmaxeval, callback=None, seed=None, memory_size=20*dimension, archive_size_ratio=2.1).optimize()\n",
    "        print(\"\\tObj NLSHADE RSP :  \", result_nlshadersp.fun)\n",
    "        #result_j20 = j2020(func.evaluate, bounds, data=None,  x0=None, populationSize=0, maxevals=Nmaxeval ).optimize()\n",
    "        #print(\"\\tObj j20 :  \", result_j20.fun)\n",
    "\n",
    "\n",
    "        result[\"ARRDE\"] = result_arrde.fun\n",
    "        result[\"LSRTDE\"] = result_lsrtde.fun\n",
    "        result[\"NLSHADE_RSP\"] = result_nlshadersp.fun\n",
    "\n",
    "        results.append(result)\n",
    "        \n",
    "        del func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate CEC Problem and Repeat for N times using multithreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionEvaluator:\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "        self.n_calls = 0\n",
    "\n",
    "    def __call__(self, X):\n",
    "        self.n_calls += 1\n",
    "        ret = self.func(np.array([X]))[0]\n",
    "        #print(X.shape, ret.shape)\n",
    "        return ret\n",
    "    \n",
    "class VectorizedEvaluator : \n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "        self.n_calls = 0\n",
    "\n",
    "    def __call__(self, X):\n",
    "        self.n_calls += X.shape[0]\n",
    "        ret = self.func(np.array(X))\n",
    "        return ret\n",
    "    \n",
    "class PyminionFunc : \n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "        self.n_calls = 0\n",
    "\n",
    "    def __call__(self, X, data=None):\n",
    "        X= np.array(X)\n",
    "        self.n_calls += X.shape[0]\n",
    "        return  self.func(X)\n",
    "    \n",
    "class VectorizedEvaluatorDE : \n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "        self.n_calls = 0\n",
    "\n",
    "    def __call__(self, X):\n",
    "        X = np.array(X).T\n",
    "        self.n_calls += X.shape[0]\n",
    "        return self.func(X)\n",
    "\n",
    "goptimum_cec22 = {\n",
    "    1 : 300, 2: 400, 3: 600, 4: 800, 5:900, 6:1800, 7:2000, 8:2200, 9:2300, 10: 2400, 11:2600, 12: 2700\n",
    "}\n",
    "goptimum_cec20 = {\n",
    "    1 : 100, 2: 1100, 3: 700, 4: 1900, 5:1700, 6:1600, 7:2100, 8:2200, 9:2400, 10: 2500\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global results variable\n",
    "results = []\n",
    "results_lock = threading.Lock()\n",
    "\n",
    "def test_optimization_threadsafe(func, bounds, dimension, func_name, Nmaxeval):\n",
    "    global results\n",
    "    result = {}\n",
    "    result['Dimensions'] = dimension\n",
    "    result['Function'] = func_name\n",
    "    # Initialize bounds\n",
    "    bounds_list = [bounds] * dimension\n",
    "    # Create wrapped function evaluator\n",
    "    evaluator = FunctionEvaluator(func)\n",
    "    vecEvaluator = VectorizedEvaluator(func)\n",
    "    vecEvaluatorDE = VectorizedEvaluatorDE(func)\n",
    "    pyminionFunc = PyminionFunc(func)\n",
    "    popsize= int(np.ceil((np.log10(Nmaxeval))**2.0+dimension/2.0))\n",
    "\n",
    "     #----------------------------------------------------------------#\n",
    "    options_LSHADE= {\n",
    "        \"memory_size\": 6, \n",
    "        \"archive_size_ratio\": 2.6, \n",
    "        \"population_reduction\" : True, \n",
    "        \"reduction_strategy\": \"linear\",\n",
    "        \"minimum_population_size\": 4, \n",
    "    }\n",
    "    \n",
    "    options_JADE =  {\n",
    "        \"mutation_strategy\": \"current_to_pbest_A1_1bin\",\n",
    "        \"archive_size_ratio\": 1.0, \n",
    "        \"population_reduction\" : True, \n",
    "        \"reduction_strategy\": \"linear\",\n",
    "        \"minimum_population_size\": dimension, \n",
    "        \"c\" : 0.1,\n",
    "    }\n",
    "\n",
    "    #pyminionFunc.n_calls =0\n",
    "    #jade = JADE (pyminionFunc, bounds_list, options=options_JADE, data=None, x0=None, population_size=0, \n",
    "    #                 maxevals=Nmaxeval, tol=0.0, callback=None, boundStrategy=\"reflect-random\", seed=None)\n",
    "    #res = jade.optimize()\n",
    "    #result['JADE'] = res.fun\n",
    "    \n",
    "    \n",
    "    #pyminionFunc.n_calls =0\n",
    "    lshade = LSHADE (pyminionFunc, bounds_list, options=options_LSHADE, data=None, x0=None, population_size=0, \n",
    "                     maxevals=Nmaxeval, tol=0.0, callback=None, boundStrategy=\"reflect-random\", seed=None)\n",
    "    res = lshade.optimize()\n",
    "    result['LSHADE'] = res.fun\n",
    "    #print(pyminionFunc.n_calls)\n",
    "    #----------------------------------------------------------------#\n",
    "\n",
    "    \n",
    "    #print(pyminionFunc.n_calls)\n",
    "    #----------------------------------------------------------------#\n",
    "\n",
    "     #----------------------------------------------------------------#\n",
    "    pyminionFunc.n_calls =0\n",
    "    lshade_rsp = NLSHADE_RSP (pyminionFunc, bounds_list, data=None, x0=None, population_size=0, \n",
    "                     maxevals=Nmaxeval, callback=None, seed=None, memory_size=20*dimension, archive_size_ratio=2.1)\n",
    "    res = lshade_rsp.optimize()\n",
    "    result['NLSHADE_RSP'] = res.fun\n",
    "    #print(pyminionFunc.n_calls)\n",
    "    #----------------------------------------------------------------#\n",
    "\n",
    "     #----------------------------------------------------------------#\n",
    "    pyminionFunc.n_calls =0\n",
    "    j20 = j2020 (pyminionFunc, bounds_list, data=None, x0=None,  \n",
    "                     maxevals=Nmaxeval, callback=None, seed=None, populationSize=0)\n",
    "    res = j20.optimize()\n",
    "    result['j2020'] = res.fun\n",
    "    #print(pyminionFunc.n_calls)\n",
    "    #----------------------------------------------------------------#\n",
    "\n",
    "     #----------------------------------------------------------------#\n",
    "    pyminionFunc.n_calls =0\n",
    "    lsrtde =LSRTDE (pyminionFunc, bounds_list, data=None, x0=None,  \n",
    "                     maxevals=Nmaxeval, callback=None, seed=None, populationSize=0)\n",
    "    res = lsrtde.optimize()\n",
    "    result['LSRTDE'] = res.fun\n",
    "    #print(pyminionFunc.n_calls)\n",
    "    #----------------------------------------------------------------#\n",
    "\n",
    "    #----------------------------------------------------------------\n",
    "    \n",
    "    pyminionFunc.n_calls=0\n",
    "    arrde = ARRDE (pyminionFunc, bounds_list, data=None, x0=None, population_size=0, \n",
    "                       maxevals=Nmaxeval, tol=0., callback=None, boundStrategy=\"reflect-random\", seed=None)\n",
    "    res = arrde.optimize()\n",
    "    result['ARRDE'] = res.fun\n",
    "    #print(pyminionFunc.n_calls)\n",
    "    #----------------------------------------------------------------#\n",
    "\n",
    "    #Differential Evolution (DE)\n",
    "    #vecEvaluatorDE.n_calls = 0\n",
    "    #de_result = differential_evolution(vecEvaluatorDE, bounds_list, popsize=3, strategy='best1bin',\n",
    "    #                                     maxiter=int(Nmaxeval/(3*dimension)), vectorized=True, updating=\"deferred\", disp=False,polish=False)\n",
    "    #result['Scipy DE'] = de_result.fun\n",
    "\n",
    "    with results_lock:\n",
    "        results.append(result)\n",
    "    print(result)\n",
    "\n",
    "Nmaxeval = 20000\n",
    "dimension = 20\n",
    "\n",
    "def run_test_optimization(j, dim):\n",
    "    cec_func = CEC2020Functions(function_number=j, dimension=dim)\n",
    "    test_optimization_threadsafe(cec_func, (-100, 100), dim, \"func_\" + str(j), Nmaxeval)\n",
    "\n",
    "\n",
    "func_numbers = [1,2,3,4,5,6,7, 8, 9,10, 11, 12] #2022\n",
    "func_numbers = [1,2,3,4,5,6,7, 8, 9,10]\n",
    "#func_numbers = [ 2,5,11, 10]\n",
    "#func_numbers = [ 9, 10]\n",
    "#func_numbers= [2, 8, 10, 11]\n",
    "#func_numbers= range(20, 30)\n",
    "Nrepeat= 11\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
    "\n",
    "    futures = []\n",
    "    for k in range(Nrepeat):\n",
    "        for j in func_numbers:\n",
    "            futures.append(executor.submit(run_test_optimization, j, dimension))\n",
    "    concurrent.futures.wait(futures)\n",
    "    for f in futures: f.result()\n",
    "\n",
    "for num in func_numbers : \n",
    "    mydict= {}\n",
    "    #algoRes = {\"NLSHADE_RSP\" : [],  \"ARRDE\":[]}\n",
    "    algoRes = {\"NLSHADE_RSP\" : [],  \"ARRDE\":[], \"j2020\":[], \"LSHADE\": [], 'Scipy DE':[],\"LSRTDE\":[] }\n",
    "    #algoRes = {\"NLSHADE_RSP\" : [],  \"ARRDE\":[], \"j2020\":[]}\n",
    "    for res in list(results) : \n",
    "        for algo in algoRes.keys() : \n",
    "            if res['Function'] == \"func_\"+str(num) :\n",
    "                algoRes[algo].append(res[algo])\n",
    "\n",
    "    full_results= {}\n",
    "    for key, val in algoRes.items() : \n",
    "        error = np.abs(np.array(val)-goptimum_cec22[num])\n",
    "        #error = error/goptimum_cec20[num]\n",
    "        error = val\n",
    "        full_results[key] = (np.min(error), np.mean(error), np.std(error))\n",
    "\n",
    "    print(\"Full results for function \"+str(num) +\":\\n\\t\", full_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curve Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dimension=21\n",
    "# Step 1: Generate data points from a polynomial \n",
    "np.random.seed(8)  # For reproducibility\n",
    "\n",
    "# True coefficients of the polynomial (degree 10)\n",
    "true_coefficients = [np.random.uniform(-1.0, 1.0)*1.0**i for i in range(dimension)]  # Random coefficients for the polynomial\n",
    "print(true_coefficients)\n",
    "\n",
    "# Generate 50 data points\n",
    "x_data = np.linspace(1e-8, 1, dimension+10)\n",
    "y_data = np.polyval(true_coefficients, x_data)\n",
    "#y_data = y_data + np.random.normal(0, np.sqrt(np.abs(y_data)))  # Add some noise\n",
    "\n",
    "# Step 2: Define the polynomial model\n",
    "def polynomial_model(x, coefficients):\n",
    "    \"\"\"Given x and coefficients, return the polynomial value.\"\"\"\n",
    "    return np.polyval(coefficients, x)\n",
    "\n",
    "# Step 3: Define the objective function to minimize\n",
    "def objective_function(coefficients, x, y):\n",
    "    \"\"\"Objective function for optimization: Sum of squared errors.\"\"\"\n",
    "    y_pred = polynomial_model(x, coefficients)\n",
    "    return np.sum((y - y_pred)**2)\n",
    "\n",
    "def objective_function_vect(coefficients, data) : \n",
    "    ret = []\n",
    "    for coeff in coefficients : \n",
    "        ret.append(objective_function(coeff, x_data, y_data))\n",
    "    return ret\n",
    "\n",
    "bounds= [(-10, 10)]*dimension\n",
    "Nmaxeval= 100000#1000*dimension\n",
    "\n",
    "# Optimize the coefficients using Nelder-Mead\n",
    "#result = opt.minimize(objective_function, np.ones(dimension), args=(x_data, y_data), method='Nelder-Mead', options={\"maxfev\":Nmaxeval, \"adaptive\":True }  ) \n",
    "\n",
    "result_arrde = ARRDE(objective_function_vect, bounds, data=None,  x0=None, population_size=0, maxevals=int(1.0*Nmaxeval), tol=0.0 ).optimize()\n",
    "#result_arrde = opt.minimize(objective_function, result_arrde.x, args=(x_data, y_data), method='Nelder-Mead', options={\"maxfev\":int(0.05*Nmaxeval), \"adaptive\":True }  ) \n",
    "\n",
    "result_lsrtde = LSRTDE(objective_function_vect, bounds, data=None,  x0=None, populationSize=0, maxevals=Nmaxeval ).optimize()\n",
    "result_lshade = LSHADE(objective_function_vect, bounds, data=None,  x0=None, population_size=0, maxevals=Nmaxeval, options= {}).optimize()\n",
    "result_nlshadersp = NLSHADE_RSP (objective_function_vect, bounds, data=None, x0=None, population_size=0, \n",
    "                     maxevals=Nmaxeval, callback=None, seed=None, memory_size=20*dimension, archive_size_ratio=2.1).optimize()\n",
    "result_j20 = j2020(objective_function_vect, bounds, data=None,  x0=None, populationSize=0, maxevals=Nmaxeval ).optimize()\n",
    "#result_de = differential_evolution(objective_function, bounds, args=(x_data, y_data), popsize=3, strategy='best1exp',\n",
    "#                                         maxiter=int(Nmaxeval/(3*dimension)), vectorized=False, disp=False,polish=False)\n",
    "\n",
    "# Step 5: Extract the fitted coefficients\n",
    "\n",
    "#fitted_coefficients_nm = result.x\n",
    "fitted_coefficients_arrde = result_arrde.x\n",
    "fitted_coefficients_lsrtde = result_lsrtde.x\n",
    "fitted_coefficients_nlshade = result_nlshadersp.x\n",
    "fitted_coefficients_j20= result_j20.x\n",
    "#fitted_coefficients_de= result_de.x\n",
    "fitted_coefficients_lshade= result_lshade.x\n",
    "\n",
    "# Step 6: Plot the results\n",
    "plt.scatter(x_data, y_data, label='Data Points')\n",
    "#plt.plot(x_data, np.polyval(true_coefficients, x_data), 'r-', label='True Polynomial')\n",
    "#plt.plot(x_data, np.polyval(fitted_coefficients_nm, x_data), 'g--', label='Fitted nm')\n",
    "plt.plot(x_data, np.polyval(fitted_coefficients_arrde, x_data), 'b--', label='Fitted arrde')\n",
    "plt.plot(x_data, np.polyval(fitted_coefficients_lsrtde, x_data), 'g--', label='Fitted LSRTDE')\n",
    "plt.plot(x_data, np.polyval(fitted_coefficients_nlshade, x_data), 'black', label='Fitted NLSHADE RSP')\n",
    "plt.plot(x_data, np.polyval(fitted_coefficients_j20, x_data), 'yellow', label='Fitted j20')\n",
    "plt.legend()\n",
    "plt.title('Polynomial Fit using Nelder-Mead')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()\n",
    "\n",
    "# Display the true and fitted coefficients\n",
    "#print(\"True coefficients:    \", true_coefficients)\n",
    "#print(\"Fitted coefficients NM :  \", fitted_coefficients_nm)\n",
    "#print(\"Fitted coefficients ARRDE :  \", fitted_coefficients_arrde)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "#print(\"Obj NM :  \",result.fun)\n",
    "print(\"Obj ARRDE :  \", result_arrde.fun)\n",
    "print(\"Obj LSRTDE :  \", result_lsrtde.fun)\n",
    "print(\"Obj NLSHADE RSP :  \", result_nlshadersp.fun)\n",
    "print(\"Obj lshade:  \", result_lshade.fun)\n",
    "print(\"Obj j20 :  \", result_j20.fun)\n",
    "#print(\"Obj de :  \", result_de.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit RBF basis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "np.random.seed(5)  # For reproducibility\n",
    "num_rbf = 20\n",
    "true_centers = 10*(-1+2*np.random.random(num_rbf))\n",
    "true_widths = np.random.rand(num_rbf) + 1.0  # Widths (variances)\n",
    "true_coeffs = 2.0*np.random.rand(num_rbf)\n",
    "print(true_centers)\n",
    "print(true_widths)\n",
    "print(true_coeffs)\n",
    "dimension= num_rbf*3\n",
    "\n",
    "# Define a Gaussian RBF function\n",
    "def rbf(x, center, width):\n",
    "    \"\"\"Compute a Gaussian RBF value given x, center, and width.\"\"\"\n",
    "    return (1.0/2.0*np.pi*width**2)*np.exp(-((x - center) ** 2) / (2 * width ** 2))\n",
    "\n",
    "# Define the function as a sum of RBFs\n",
    "def rbf_sum(x, centers, widths, coeffs):\n",
    "    \"\"\"Sum of Gaussian RBFs.\"\"\"\n",
    "    result = np.zeros_like(x)\n",
    "    coeffs= np.array(coeffs)\n",
    "    norm_coeff = coeffs/np.sum(coeffs)\n",
    "    for i in range(len(centers)):\n",
    "        result += norm_coeff[i] * rbf(x, centers[i], widths[i])\n",
    "    return result\n",
    "\n",
    "\n",
    "# Generate 50 data points\n",
    "x_data = np.linspace(-20, 20,dimension+50)\n",
    "y_data = rbf_sum(x_data, true_centers, true_widths, true_coeffs)  # Add some noise\n",
    "\n",
    "\n",
    "# Step 2: Define the model for fitting\n",
    "def rbf_model(x, params):\n",
    "    \"\"\"RBF model with combined parameters (centers, widths, and coefficients).\"\"\"\n",
    "    num_rbf = len(params) // 3\n",
    "    centers = params[:num_rbf]\n",
    "    widths = params[num_rbf:2*num_rbf]\n",
    "    coeffs = params[2*num_rbf:]\n",
    "    return rbf_sum(x, centers, widths, coeffs)\n",
    "\n",
    "def rbf_data(params):\n",
    "    \"\"\"RBF model with combined parameters (centers, widths, and coefficients).\"\"\"\n",
    "    num_rbf = len(params) // 3\n",
    "    centers = params[:num_rbf]\n",
    "    widths = params[num_rbf:2*num_rbf]\n",
    "    coeffs = params[2*num_rbf:]\n",
    "    return rbf_sum(x_data, centers, widths, coeffs)\n",
    "\n",
    "# Step 3: Define the objective function to minimize\n",
    "def objective_function(params):\n",
    "    \"\"\"Objective function for optimization: Sum of squared errors.\"\"\"\n",
    "    y_pred = rbf_model(x_data, params)\n",
    "    return np.sum((y_data - y_pred) ** 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "executor = concurrent.futures.ThreadPoolExecutor(max_workers=4)\n",
    "def objective_function_vect(params, data) : \n",
    "    #ret = []\n",
    "    #for p in params : \n",
    "    #    ret.append(objective_function(p, x_data, y_data))\n",
    "    ret = list(executor.map(objective_function, params))\n",
    "    return ret\n",
    "\n",
    "\n",
    "initial_guess = np.concatenate([\n",
    "    np.linspace(-100, 100, num_rbf),  # Initial guess for centers\n",
    "    np.ones(num_rbf),  # Initial guess for widths\n",
    "    np.zeros(num_rbf)  # Initial guess for coefficients\n",
    "])\n",
    "\n",
    "\n",
    "bounds= [(-10, 10)]*dimension\n",
    "Nmaxeval=500000#5000*dimension\n",
    "\n",
    "# Optimize the coefficients using Nelder-Mead\n",
    "\n",
    "#result = opt.minimize(objective_function, initial_guess, args=(), method='Nelder-Mead', options={\"maxfev\":Nmaxeval, \"adaptive\":True }  ) \n",
    "#print(\"SIMPLEX done\")\n",
    "result_arrde = ARRDE(objective_function_vect, bounds, data=None,  x0=None, population_size=0, maxevals=Nmaxeval, tol=0.0 ).optimize()\n",
    "print(\"ARRDE done\")\n",
    "result_lsrtde = LSRTDE(objective_function_vect, bounds, data=None,  x0=None, populationSize=0, maxevals=Nmaxeval ).optimize()\n",
    "print(\"LSRTDE done\")\n",
    "result_lshade = LSHADE(objective_function_vect, bounds, data=None,  x0=None, population_size=0, maxevals=Nmaxeval, options= {}).optimize()\n",
    "print(\"LSHADE done\")\n",
    "result_nlshadersp = NLSHADE_RSP (objective_function_vect, bounds, data=None, x0=None, population_size=0, \n",
    "                     maxevals=Nmaxeval, callback=None, seed=None, memory_size=20*dimension, archive_size_ratio=2.1).optimize()\n",
    "print(\"RSP done\")\n",
    "result_j20 = j2020(objective_function_vect, bounds, data=None,  x0=None, populationSize=0, maxevals=Nmaxeval ).optimize()\n",
    "print(\"j20 done\")\n",
    "#result_de = differential_evolution(objective_function, bounds, args=(x_data, y_data), popsize=1, strategy='best1bin',\n",
    "#                                         maxiter=int(Nmaxeval/(3*dimension)), vectorized=False, disp=False,polish=False)\n",
    "#print(\"DE done\")\n",
    "\n",
    "plt.plot(x_data, y_data, label=\"data\", color=\"black\")\n",
    "plt.plot(x_data, rbf_data(result_arrde.x), label=\"ARRDE\")\n",
    "plt.plot(x_data, rbf_data(result_lsrtde.x), label=\"LSRTDE\")\n",
    "plt.plot(x_data, rbf_data(result_nlshadersp.x), label=\"NLSHADE RSP\")\n",
    "#plt.plot(x_data, rbf_data(result_j20.x), label=\"j2020\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "#\n",
    "#print(\"Obj NM :  \",result.fun)\n",
    "print(\"Obj ARRDE :  \", result_arrde.fun)\n",
    "print(\"Obj LSRTDE :  \", result_lsrtde.fun)\n",
    "print(\"Obj NLSHADE RSP :  \", result_nlshadersp.fun)\n",
    "print(\"Obj lshade:  \", result_lshade.fun)\n",
    "#print(\"Obj j20 :  \", result_j20.fun)\n",
    "#print(\"Obj de :  \", result_de.fun)\n",
    "\n",
    "executor.shutdown()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import scipy.optimize as opt\n",
    "from scipy.optimize import differential_evolution, minimize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fix the random seed for reproducibility\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Generate data points from a polynomial of degree 10\n",
    "def generate_polynomial_data(x, coefficients):\n",
    "    \"\"\"Generates data points based on a polynomial function.\"\"\"\n",
    "    y = np.zeros_like(x)\n",
    "    for i, coeff in enumerate(coefficients):\n",
    "        y += coeff * x ** i\n",
    "    return y\n",
    "\n",
    "# True polynomial coefficients\n",
    "true_coeffs = np.random.randn(11)  # Degree 10 polynomial has 11 coefficients\n",
    "print(\"True coefficients: \", true_coeffs)\n",
    "\n",
    "# Generate 50 data points\n",
    "x_data = np.linspace(-10, 10, 50)\n",
    "y_data = generate_polynomial_data(x_data, true_coeffs)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "x_tensor = torch.tensor(x_data, dtype=torch.float32).unsqueeze(1)  # (50, 1)\n",
    "y_tensor = torch.tensor(y_data, dtype=torch.float32).unsqueeze(1)  # (50, 1)\n",
    "\n",
    "# Define a simple neural network with a single hidden layer\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the neural network\n",
    "num_hidden = 10\n",
    "nn = SimpleNN(num_inputs=1, num_hidden=num_hidden, num_outputs=1)\n",
    "\n",
    "# Define the objective function for optimization\n",
    "def nn_objective_function(params, x, y, nn_model):\n",
    "    \"\"\"Objective function: Mean Squared Error between predictions and true values.\"\"\"\n",
    "    # Update the network weights and biases from flattened params\n",
    "    with torch.no_grad():\n",
    "        start = 0\n",
    "        \n",
    "        # Extract weights and biases for the first layer\n",
    "        nn_model.fc1.weight.data = torch.tensor(params[start:start + 1 * num_hidden].reshape(1, num_hidden), dtype=torch.float32)\n",
    "        start += 1 * num_hidden\n",
    "        nn_model.fc1.bias.data = torch.tensor(params[start:start + num_hidden], dtype=torch.float32)\n",
    "        start += num_hidden\n",
    "        \n",
    "        # Extract weights and biases for the second layer\n",
    "        nn_model.fc2.weight.data = torch.tensor(params[start:start + num_hidden * 1].reshape(num_hidden, 1), dtype=torch.float32)\n",
    "        start += num_hidden * 1\n",
    "        nn_model.fc2.bias.data = torch.tensor(params[start:start + 1], dtype=torch.float32)\n",
    "    \n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        y_pred = nn_model(x).detach()\n",
    "    loss = torch.mean((y - y_pred) ** 2).item()\n",
    "    return loss\n",
    "\n",
    "# Flatten the network parameters into a single vector\n",
    "def flatten_params(nn_model):\n",
    "    \"\"\"Flatten the network parameters into a single vector.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        fc1_weight = nn_model.fc1.weight.data.numpy().flatten()\n",
    "        fc1_bias = nn_model.fc1.bias.data.numpy()\n",
    "        fc2_weight = nn_model.fc2.weight.data.numpy().flatten()\n",
    "        fc2_bias = nn_model.fc2.bias.data.numpy()\n",
    "    return np.concatenate([fc1_weight, fc1_bias, fc2_weight, fc2_bias])\n",
    "\n",
    "# Unflatten parameters back into network weights\n",
    "def unflatten_params(nn_model, params):\n",
    "    \"\"\"Unflatten the parameter vector back into weights and biases.\"\"\"\n",
    "    start = 0\n",
    "    \n",
    "    # Extract weights and biases for the first layer\n",
    "    nn_model.fc1.weight.data = torch.tensor(params[start:start + 1 * num_hidden].reshape(1, num_hidden), dtype=torch.float32)\n",
    "    start += 1 * num_hidden\n",
    "    nn_model.fc1.bias.data = torch.tensor(params[start:start + num_hidden], dtype=torch.float32)\n",
    "    start += num_hidden\n",
    "    \n",
    "    # Extract weights and biases for the second layer\n",
    "    nn_model.fc2.weight.data = torch.tensor(params[start:start + num_hidden * 1].reshape(num_hidden, 1), dtype=torch.float32)\n",
    "    start += num_hidden * 1\n",
    "    nn_model.fc2.bias.data = torch.tensor(params[start:start + 1], dtype=torch.float32)\n",
    "\n",
    "# Initial guess for optimization\n",
    "initial_guess = flatten_params(nn)\n",
    "\n",
    "# Define bounds for parameters (for Differential Evolution)\n",
    "bounds = [(-5, 5)] * len(initial_guess)\n",
    "\n",
    "# Optimize the parameters using Nelder-Mead\n",
    "result_nm = opt.minimize(nn_objective_function, initial_guess, args=(x_tensor, y_tensor, nn), method='Nelder-Mead')\n",
    "\n",
    "# Optimize the parameters using Differential Evolution\n",
    "result_de = differential_evolution(nn_objective_function, bounds, args=(x_tensor, y_tensor, nn), popsize=3, strategy='best1exp',\n",
    "                                     maxiter=1000, vectorized=False, disp=False, polish=False)\n",
    "\n",
    "# Define the BFGS optimization function\n",
    "def bfgs_optimize(nn, x, y):\n",
    "    \"\"\"Optimize using BFGS.\"\"\"\n",
    "    def objective_function(params):\n",
    "        return nn_objective_function(params, x, y, nn)\n",
    "    \n",
    "    result_bfgs = minimize(objective_function, flatten_params(nn), method='BFGS', options={'disp': True})\n",
    "    return result_bfgs\n",
    "\n",
    "# Optimize the parameters using BFGS\n",
    "result_bfgs = bfgs_optimize(nn, x_tensor, y_tensor)\n",
    "\n",
    "# Optimize the parameters using Adam (PyTorch optimizer)\n",
    "def train_with_adam(nn, x, y, num_epochs=1000, learning_rate=0.01):\n",
    "    \"\"\"Train the neural network using Adam optimizer.\"\"\"\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(nn.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        nn.train()\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = nn(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return nn\n",
    "\n",
    "# Train the model using Adam optimizer\n",
    "nn_adam = SimpleNN(num_inputs=1, num_hidden=num_hidden, num_outputs=1)\n",
    "trained_nn_adam = train_with_adam(nn_adam, x_tensor, y_tensor)\n",
    "\n",
    "# Predict with the optimized parameters and plot the results\n",
    "def predict_with_nn(nn_model, x):\n",
    "    \"\"\"Predict with the neural network.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        nn_model.eval()\n",
    "        y_pred = nn_model(torch.tensor(x, dtype=torch.float32).unsqueeze(1)).numpy()\n",
    "    return y_pred\n",
    "\n",
    "# Update network parameters and predict using the results from optimization\n",
    "unflatten_params(nn, result_nm.x)\n",
    "y_pred_nm = predict_with_nn(nn, x_data)\n",
    "\n",
    "unflatten_params(nn, result_de.x)\n",
    "y_pred_de = predict_with_nn(nn, x_data)\n",
    "\n",
    "unflatten_params(nn, result_bfgs.x)\n",
    "y_pred_bfgs = predict_with_nn(nn, x_data)\n",
    "\n",
    "# Adam predictions\n",
    "y_pred_adam = predict_with_nn(trained_nn_adam, x_data)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(x_data, y_data, 'bo', label='True Data')\n",
    "plt.plot(x_data, y_pred_nm, 'r-', label='Nelder-Mead Fit')\n",
    "plt.plot(x_data, y_pred_de, 'g-', label='Differential Evolution Fit')\n",
    "plt.plot(x_data, y_pred_bfgs, 'm-', label='BFGS Fit')\n",
    "plt.plot(x_data, y_pred_adam, 'c-', label='Adam Fit')\n",
    "plt.legend()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Neural Network Fit to Polynomial Data')\n",
    "plt.show()\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nOptimization Results:\")\n",
    "print(\"Nelder-Mead Objective:\", result_nm.fun)\n",
    "print(\"Differential Evolution Objective:\", result_de.fun)\n",
    "print(\"BFGS Objective:\", result_bfgs.fun)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CEC 2011 Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "def func_1(x):\n",
    "    d = len(x)\n",
    "    if d < 6:\n",
    "        print('dimension-size should be six.')\n",
    "        return None\n",
    "    elif d > 6:\n",
    "        print('dimension-size is more than 6.')\n",
    "        print('function has been evaluated on first six dimensions.')\n",
    "        x = x[:, :6]\n",
    "    \n",
    "    theta = 2 * np.pi / 100\n",
    "    f = 0\n",
    "    for t in range(101):\n",
    "        y_t = x[0] * np.sin(x[1] * t * theta + x[2] * np.sin(x[3] * t * theta + x[4] * np.sin(x[5] * t * theta)))\n",
    "        y_0_t = np.sin(5 * t * theta - 1.5 * np.sin(4.8 * t * theta + 2 * np.sin(4.9 * t * theta)))\n",
    "        f += (y_t - y_0_t) ** 2\n",
    "    \n",
    "    return f\n",
    "\n",
    "def func_2(x):\n",
    "    d = len(x)\n",
    "    if d % 3 != 0:\n",
    "        print('x passed to this function must be n dimensional array where n is perfectly divisible by 3.')\n",
    "        return None\n",
    "    \n",
    "    n = d // 3\n",
    "    x = np.array(x).reshape(-1, 3)\n",
    "    r = squareform(pdist(x))\n",
    "    a = np.ones((n, n))\n",
    "    b = np.full((n, n), 2)\n",
    "    v = 0\n",
    "    for i in range(n-1):\n",
    "        for j in range(i+1, n):\n",
    "            v += (a[i, j] / r[i, j]**12) - (b[i, j] / r[i, j]**6)\n",
    "    \n",
    "    return v\n",
    "\n",
    "def func_5 (x) :\n",
    "    d = len(x)\n",
    "    if d % 3 != 0:\n",
    "        print('x passed to this function must be n dimensional array where n is perfectly divisible by 3.')\n",
    "        return None\n",
    "    \n",
    "    NP = d // 3\n",
    "    x = np.array(x).reshape(-1, 3)\n",
    "    R1 = 3.0\n",
    "    R2 = 0.2\n",
    "    A = 3.2647e+3\n",
    "    B = 9.5373e+1\n",
    "    lemda1 = 3.2394\n",
    "    lemda2 = 1.3258\n",
    "    lemda3 = 1.3258\n",
    "    c = 4.8381\n",
    "    d = 2.0417\n",
    "    n1 = 22.956\n",
    "    gama = 0.33675\n",
    "    h = 0\n",
    "    E = np.zeros(NP)\n",
    "    r = np.zeros((NP, NP))\n",
    "    fcr = np.zeros((NP, NP))\n",
    "    VRr = np.zeros((NP, NP))\n",
    "    VAr = np.zeros((NP, NP))\n",
    "\n",
    "    for i in range(NP):\n",
    "        for j in range(NP):\n",
    "            r[i, j] = np.linalg.norm(x[i] - x[j])\n",
    "            if r[i, j] < (R1 - R2):\n",
    "                fcr[i, j] = 1\n",
    "            elif r[i, j] > (R1 + R2):\n",
    "                fcr[i, j] = 0\n",
    "            else:\n",
    "                fcr[i, j] = 0.5 - 0.5 * np.sin(np.pi/2 * (r[i, j] - R1) / R2)\n",
    "\n",
    "            VRr[i, j] = A * np.exp(-lemda1 * r[i, j])\n",
    "            VAr[i, j] = B * np.exp(-lemda2 * r[i, j])\n",
    "    \n",
    "    for i in range(NP):\n",
    "        for j in range(NP):\n",
    "            if i == j:\n",
    "                continue\n",
    "            jeta = np.zeros((NP, NP))\n",
    "            for k in range(NP):\n",
    "                if i == k or j == k:\n",
    "                    continue\n",
    "                rd1 = np.linalg.norm(x[i] - x[k])\n",
    "                rd3 = np.linalg.norm(x[k] - x[j])\n",
    "                rd2 = np.linalg.norm(x[i] - x[j])\n",
    "                ctheta_ijk = (rd1**2 + rd2**2 - rd3**3) / (2 * rd1 * rd2)\n",
    "                G_th_ijk = 1 + (c**2) / (d**2) - (c**2) / (d**2 + (h - ctheta_ijk)**2)\n",
    "                jeta[i, j] += fcr[i, k] * G_th_ijk * np.exp(lemda3**3 * (r[i, j] - r[i, k])**3)\n",
    "            \n",
    "            Bij = (1 + (gama * jeta[i, j])**n1)**(-0.5/n1)\n",
    "            E[i] += fcr[i, j] * (VRr[i, j] - Bij * VAr[i, j]) / 2\n",
    "    \n",
    "    return np.sum(E)\n",
    "\n",
    "def func_6 (x) :\n",
    "    d = len(x)\n",
    "    if d % 3 != 0:\n",
    "        print('x passed to this function must be n dimensional array where n is perfectly divisible by 3.')\n",
    "        return None\n",
    "    \n",
    "    NP = d // 3\n",
    "    x = np.array(x).reshape(-1, 3)\n",
    "    R1 = 2.85\n",
    "    R2 = 0.15\n",
    "    A = 1.8308e+3\n",
    "    B = 4.7118e+2\n",
    "    lemda1 = 2.4799\n",
    "    lemda2 = 1.7322\n",
    "    lemda3 = 1.7322\n",
    "    c = 1.0039e+05\n",
    "    d = 1.6218e+01\n",
    "    n1 = 7.8734e-01\n",
    "    gama = 1.0999e-06\n",
    "    h = -5.9826e-01\n",
    "    E = np.zeros(NP)\n",
    "    r = np.zeros((NP, NP))\n",
    "    fcr = np.zeros((NP, NP))\n",
    "    VRr = np.zeros((NP, NP))\n",
    "    VAr = np.zeros((NP, NP))\n",
    "\n",
    "    for i in range(NP):\n",
    "        for j in range(NP):\n",
    "            r[i, j] = np.linalg.norm(x[i] - x[j])\n",
    "            if r[i, j] < (R1 - R2):\n",
    "                fcr[i, j] = 1\n",
    "            elif r[i, j] > (R1 + R2):\n",
    "                fcr[i, j] = 0\n",
    "            else:\n",
    "                fcr[i, j] = 0.5 - 0.5 * np.sin(np.pi/2 * (r[i, j] - R1) / R2)\n",
    "\n",
    "            VRr[i, j] = A * np.exp(-lemda1 * r[i, j])\n",
    "            VAr[i, j] = B * np.exp(-lemda2 * r[i, j])\n",
    "    \n",
    "    for i in range(NP):\n",
    "        for j in range(NP):\n",
    "            if i == j:\n",
    "                continue\n",
    "            jeta = np.zeros((NP, NP))\n",
    "            for k in range(NP):\n",
    "                if i == k or j == k:\n",
    "                    continue\n",
    "                rd1 = np.linalg.norm(x[i] - x[k])\n",
    "                rd3 = np.linalg.norm(x[k] - x[j])\n",
    "                rd2 = np.linalg.norm(x[i] - x[j])\n",
    "                ctheta_ijk = (rd1**2 + rd2**2 - rd3**3) / (2 * rd1 * rd2)\n",
    "                G_th_ijk = 1 + (c**2) / (d**2) - (c**2) / (d**2 + (h - ctheta_ijk)**2)\n",
    "                jeta[i, j] += fcr[i, k] * G_th_ijk * np.exp(lemda3**3 * (r[i, j] - r[i, k])**3)\n",
    "            \n",
    "            Bij = (1 + (gama * jeta[i, j])**n1)**(-0.5/n1)\n",
    "            E[i] += fcr[i, j] * (VRr[i, j] - Bij * VAr[i, j]) / 2\n",
    "    \n",
    "    return np.sum(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds_1 = [(-6.4, 6.35)]*6\n",
    "\n",
    "lb_2 = [ 0., 0.,  0.,   -4.,   -4., -4. ,  -4. ,  -4.25, -4.25, -4.25, -4.5 , -4.5,\n",
    " -4.5,  -4.75, -4.75, -4.75, -5.,   -5.,  -5.,  -5.25, -5.25, -5.25, -5.5,  -5.5,\n",
    " -5.5, -5.75, -5.75, -5.75, -6.,  -6.  ]\n",
    "ub_2 = [4.,  4.  ,       3.14159265 , 4. ,        4.  ,       4.,\n",
    " 4.   , 4.25   ,    4.25   ,    4.25 ,      4.5    ,    4.5,\n",
    " 4.5 ,       4.75,       4.75 ,      4.75,       5.   ,      5.,\n",
    " 5.  ,       5.25  ,     5.25 ,      5.25,       5.5 ,     5.5,\n",
    " 5.5 ,       5.75 ,      5.75 ,      5.75 ,      6. ,        6.        ]\n",
    "\n",
    "bounds_2 = list(zip(lb_2, ub_2))\n",
    "bounds_5 = [(0.0, 4.0),\n",
    " (0.0, 4.0),\n",
    " (0.0, 3.141592653589793),\n",
    " (-1.0, 4.0),\n",
    " (-1.0, 4.0),\n",
    " (-1.0, 4.0),\n",
    " (-1.0, 4.0),\n",
    " (-1.0, 4.25),\n",
    " (-1.0, 4.25),\n",
    " (-1.0, 4.25),\n",
    " (-1.0, 4.5),\n",
    " (-1.0, 4.5),\n",
    " (-1.0, 4.5),\n",
    " (-1.0, 4.75),\n",
    " (-1.0, 4.75),\n",
    " (-1.0, 4.75),\n",
    " (-1.0, 5.0),\n",
    " (-1.0, 5.0),\n",
    " (-1.0, 5.0),\n",
    " (-1.0, 5.25),\n",
    " (-1.0, 5.25),\n",
    " (-1.0, 5.25),\n",
    " (-1.0, 5.5),\n",
    " (-1.0, 5.5),\n",
    " (-1.0, 5.5),\n",
    " (-1.0, 5.75),\n",
    " (-1.0, 5.75),\n",
    " (-1.0, 5.75),\n",
    " (-1.0, 6.0),\n",
    " (-1.0, 6.0)]\n",
    "\n",
    "dimension_1 = 6\n",
    "dimension_2 = 30 \n",
    "dimension_5=30 \n",
    "dimension_6 = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension=dimension_1\n",
    "# Step 3: Define the objective function to minimize\n",
    "def objective_function(x):\n",
    "    \"\"\"Objective function for optimization: Sum of squared errors.\"\"\"\n",
    "    return func_1(x)\n",
    "\n",
    "executor = concurrent.futures.ThreadPoolExecutor(max_workers=10)\n",
    "def objective_function_vect(xs, data):\n",
    "    ret = list(executor.map(objective_function, xs))\n",
    "    return ret\n",
    "\n",
    "bounds=  bounds_1\n",
    "Nmaxeval=50000#3000*dimension\n",
    "\n",
    "# Optimize the coefficients using Nelder-Mead\n",
    "initial_guess = [1.0 for i in range(dimension)]\n",
    "\n",
    "#result =minimize(objective_function, initial_guess, args=(), method='Nelder-Mead', options={\"maxfev\":Nmaxeval, \"adaptive\":True }  ) \n",
    "#print(\"SIMPLEX done\")\n",
    "result_arrde = ARRDE(objective_function_vect, bounds, data=None,  x0=None, population_size=0, maxevals=Nmaxeval, tol=0.0 ).optimize()\n",
    "print(\"Obj ARRDE :  \", result_arrde.fun)\n",
    "result_lsrtde = LSRTDE(objective_function_vect, bounds, data=None,  x0=None, populationSize=0, maxevals=Nmaxeval ).optimize()\n",
    "print(\"Obj LSRTDE :  \", result_lsrtde.fun)\n",
    "#result_lshade = LSHADE(objective_function_vect, bounds, data=None,  x0=None, population_size=0, maxevals=Nmaxeval, options= {}).optimize()\n",
    "#print(\"LSHADE done\")\n",
    "result_nlshadersp = NLSHADE_RSP (objective_function_vect, bounds, data=None, x0=None, population_size=0, \n",
    "                     maxevals=Nmaxeval, callback=None, seed=None, memory_size=20*dimension, archive_size_ratio=2.1).optimize()\n",
    "print(\"Obj NLSHADE RSP :  \", result_nlshadersp.fun)\n",
    "result_j20 = j2020(objective_function_vect, bounds, data=None,  x0=None, populationSize=0, maxevals=Nmaxeval ).optimize()\n",
    "print(\"Obj j20 :  \", result_j20.fun)\n",
    "#result_de = differential_evolution(objective_function, bounds, args=(), popsize=1, strategy='best1bin',\n",
    "#                                         maxiter=int(Nmaxeval/(3*dimension)), vectorized=False, disp=False,polish=False)\n",
    "#print(\"DE done\")\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "#print(\"Obj NM :  \",result.fun)\n",
    "\n",
    "\n",
    "\n",
    "#print(\"Obj lshade:  \", result_lshade.fun)\n",
    "\n",
    "#print(\"Obj de :  \", result_de.fun)\n",
    "executor.shutdown(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
