{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"./../\")\n",
    "sys.path.append(\"./../external\")\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.optimize import differential_evolution, minimize\n",
    "import matplotlib.pyplot as plt\n",
    "from pyminion import *\n",
    "import concurrent.futures\n",
    "import threading\n",
    "#from cec_2011 import * #commmet out this line if you do not have matlab installed\n",
    "import pandas as pd\n",
    "from pyminion.test import MWUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CEC2011\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "for j in range(31):\n",
    "    for i in range(1, 23):\n",
    "    #for i in  [1, 2,3, 4, 5, 6, 7, 10, 21, 22 ]:\n",
    "        if i in [3,4] : continue\n",
    "        result = {}\n",
    "        func = CEC2011(function_number=i, max_workers=10)\n",
    "        bounds = func.getBounds()\n",
    "        dimension = func.dimension\n",
    "        Nmaxeval=50000\n",
    "        if (dimension<10): Nmaxeval=50000\n",
    "        if (i==3 or i==4):  Nmaxeval=2000\n",
    "        \n",
    "        result['Dimensions'] = dimension\n",
    "        result['Function_number'] = i\n",
    "        print(\"--------------------- Function : \", i, \", dimension : \", dimension, \", maxevals : \", Nmaxeval, \"----------------\")\n",
    "        #result =minimize(objective_function, initial_guess, args=(), method='Nelder-Mead', options={\"maxfev\":Nmaxeval, \"adaptive\":True }  ) \n",
    "        #print(\"SIMPLEX done\")\n",
    "        result_arrde = ARRDE(func.evaluate, bounds, data=None,  x0=None, population_size=0, maxevals=Nmaxeval, tol=0.0 ).optimize()\n",
    "        print(\"\\tObj ARRDE :  \", result_arrde.fun)\n",
    "        result_lsrtde = LSRTDE(func.evaluate, bounds, data=None,  x0=None, populationSize=0, maxevals=Nmaxeval ).optimize()\n",
    "        print(\"\\tObj LSRTDE :  \", result_lsrtde.fun)\n",
    "        result_lshade = LSHADE(func.evaluate, bounds, data=None,  x0=None, population_size=0, maxevals=Nmaxeval, options= {}).optimize()\n",
    "        print(\"\\tObj LSHADE :  \", result_lshade.fun)\n",
    "        result_nlshadersp = NLSHADE_RSP (func.evaluate, bounds, data=None, x0=None, population_size=0, \n",
    "                            maxevals=Nmaxeval, callback=None, seed=None, memory_size=20*dimension, archive_size_ratio=2.1).optimize()\n",
    "        print(\"\\tObj NLSHADE RSP :  \", result_nlshadersp.fun)\n",
    "        #result_j20 = j2020(func.evaluate, bounds, data=None,  x0=None, populationSize=0, maxevals=Nmaxeval ).optimize()\n",
    "        #print(\"\\tObj j20 :  \", result_j20.fun)\n",
    "\n",
    "\n",
    "        result[\"ARRDE\"] = result_arrde.fun\n",
    "        result[\"LSRTDE\"] = result_lsrtde.fun\n",
    "        result[\"LSHADE\"] = result_lshade.fun\n",
    "        result[\"NLSHADE_RSP\"] = result_nlshadersp.fun\n",
    "        #result[\"j2020\"] = result_j20.fun\n",
    "\n",
    "        results.append(result)\n",
    "        print(\"\")\n",
    "        del func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict= {}\n",
    "algoRes = {\"NLSHADE_RSP\" : [],  \"ARRDE\":[], \"LSHADE\": [], \"LSRTDE\":[] }\n",
    "\n",
    "for algo in algoRes.keys() :\n",
    "    for num in [1, 2,5, 6, 7, 10, 21, 22 ] : \n",
    "        ar = []\n",
    "        for res in results : \n",
    "            if res[\"Function_number\"]== num : ar.append(res[algo])\n",
    "        algoRes[algo].append(ar)\n",
    "\n",
    "\n",
    "\n",
    "    #print(\"Full results for function \"+str(num) +\":\\n\\t\", full_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algoResFinal = {}\n",
    "for algo, mat in algoRes.items() : algoResFinal[algo] = np.array(mat)\n",
    "dfarr = {}\n",
    "dfarr_test = {}\n",
    "for algo, mat in algoResFinal.items() : \n",
    "    res = []\n",
    "    res_test = []\n",
    "    for i, num in enumerate([1, 2,5, 6, 7, 10, 21, 22 ]) : \n",
    "        res_test.append(MWUT(algoResFinal[\"ARRDE\"][i], mat[i]))\n",
    "        res.append(np.mean(mat[i]))\n",
    "    dfarr_test[algo] = res_test\n",
    "    dfarr[algo] = res\n",
    "\n",
    "df = pd.DataFrame(dfarr)\n",
    "display(df)\n",
    "\n",
    "df_test = pd.DataFrame(dfarr_test)\n",
    "display(df_test)\n",
    "\n",
    "for algo in df_test.columns : \n",
    "    print(algo, \" : \", np.mean(df_test[algo]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "for j in range(11):\n",
    "    #for i in range(1, 23):\n",
    "    for i in  [8,9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20 ]:\n",
    "        if i in [3,4] : continue\n",
    "        result = {}\n",
    "        func = CEC2011(function_number=i, max_workers=5)\n",
    "        bounds = func.getBounds()\n",
    "        dimension = func.dimension\n",
    "        Nmaxeval=50000\n",
    "        if (dimension<10): Nmaxeval=50000\n",
    "        if (i==3 or i==4):  Nmaxeval=500\n",
    "        \n",
    "        result['Dimensions'] = dimension\n",
    "        result['Function_number'] = i\n",
    "        print(\"--------------------- Function : \", i, \", dimension : \", dimension, \", maxevals : \", Nmaxeval, \"----------------\")\n",
    "        #result =minimize(objective_function, initial_guess, args=(), method='Nelder-Mead', options={\"maxfev\":Nmaxeval, \"adaptive\":True }  ) \n",
    "        #print(\"SIMPLEX done\")\n",
    "        result_arrde = ARRDE(func.evaluate, bounds, data=None,  x0=None, population_size=0, maxevals=Nmaxeval, tol=0.0 ).optimize()\n",
    "        print(\"\\tObj ARRDE :  \", result_arrde.fun)\n",
    "        result_lsrtde = LSRTDE(func.evaluate, bounds, data=None,  x0=None, populationSize=0, maxevals=Nmaxeval ).optimize()\n",
    "        print(\"\\tObj LSRTDE :  \", result_lsrtde.fun)\n",
    "        result_lshade = LSHADE(func.evaluate, bounds, data=None,  x0=None, population_size=0, maxevals=Nmaxeval, options= {}).optimize()\n",
    "        print(\"\\tObj LSHADE :  \", result_lshade.fun)\n",
    "        result_nlshadersp = NLSHADE_RSP (func.evaluate, bounds, data=None, x0=None, population_size=0, \n",
    "                            maxevals=Nmaxeval, callback=None, seed=None, memory_size=20*dimension, archive_size_ratio=2.1).optimize()\n",
    "        print(\"\\tObj NLSHADE RSP :  \", result_nlshadersp.fun)\n",
    "        #result_j20 = j2020(func.evaluate, bounds, data=None,  x0=None, populationSize=0, maxevals=Nmaxeval ).optimize()\n",
    "        #print(\"\\tObj j20 :  \", result_j20.fun)\n",
    "\n",
    "\n",
    "        result[\"ARRDE\"] = result_arrde.fun\n",
    "        result[\"LSRTDE\"] = result_lsrtde.fun\n",
    "        result[\"LSHADE\"] = result_lshade.fun\n",
    "        result[\"NLSHADE_RSP\"] = result_nlshadersp.fun\n",
    "        #result[\"j2020\"] = result_j20.fun\n",
    "\n",
    "        results.append(result)\n",
    "        print(\"\")\n",
    "        del func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict= {}\n",
    "algoRes = {\"NLSHADE_RSP\" : [],  \"ARRDE\":[], \"LSHADE\": [], \"LSRTDE\":[] }\n",
    "\n",
    "for algo in algoRes.keys() :\n",
    "    for num in [8,9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20 ] : \n",
    "        ar = []\n",
    "        for res in results : \n",
    "            if res[\"Function_number\"]== num : ar.append(res[algo])\n",
    "        algoRes[algo].append(ar)\n",
    "\n",
    "       \n",
    "print(algoRes)\n",
    "\n",
    "    #print(\"Full results for function \"+str(num) +\":\\n\\t\", full_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algoResFinal = {}\n",
    "for algo, mat in algoRes.items() : algoResFinal[algo] = np.array(mat)\n",
    "dfarr = {}\n",
    "dfarr_test = {}\n",
    "for algo, mat in algoResFinal.items() : \n",
    "    np.savetxt(algo+\"_cec2011_3.txt\", mat.T )\n",
    "    res = []\n",
    "    res_test = []\n",
    "    for i, num in enumerate([8,9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20 ]) : \n",
    "        res_test.append(MWUT(algoResFinal[\"ARRDE\"][i], mat[i]))\n",
    "        res.append(np.mean(mat[i]))\n",
    "    dfarr_test[algo] = res_test\n",
    "    dfarr[algo] = res\n",
    "\n",
    "df = pd.DataFrame(dfarr)\n",
    "display(df)\n",
    "\n",
    "df_test = pd.DataFrame(dfarr_test)\n",
    "display(df_test)\n",
    "\n",
    "for algo in df_test.columns : \n",
    "    print(algo, \" : \", np.mean(df_test[algo]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "for j in range(11):\n",
    "    #for i in range(1, 23):\n",
    "    for i in  [3,4 ]:\n",
    "        #if i in [3,4] : continue\n",
    "        result = {}\n",
    "        func = CEC2011(function_number=i, max_workers=8)\n",
    "        bounds = func.getBounds()\n",
    "        dimension = func.dimension\n",
    "        Nmaxeval=50000\n",
    "        if (dimension<10): Nmaxeval=50000\n",
    "        if (i==3 or i==4):  Nmaxeval=1000\n",
    "        \n",
    "        result['Dimensions'] = dimension\n",
    "        result['Function_number'] = i\n",
    "        print(\"--------------------- Function : \", i, \", dimension : \", dimension, \", maxevals : \", Nmaxeval, \"----------------\")\n",
    "        #result =minimize(objective_function, initial_guess, args=(), method='Nelder-Mead', options={\"maxfev\":Nmaxeval, \"adaptive\":True }  ) \n",
    "        #print(\"SIMPLEX done\")\n",
    "        result_arrde = ARRDE(func.evaluate, bounds, data=None,  x0=None, population_size=0, maxevals=Nmaxeval, tol=0.0 ).optimize()\n",
    "        print(\"\\tObj ARRDE :  \", result_arrde.fun)\n",
    "        result_lsrtde = LSRTDE(func.evaluate, bounds, data=None,  x0=None, populationSize=0, maxevals=Nmaxeval ).optimize()\n",
    "        print(\"\\tObj LSRTDE :  \", result_lsrtde.fun)\n",
    "        result_lshade = LSHADE(func.evaluate, bounds, data=None,  x0=None, population_size=0, maxevals=Nmaxeval, options= {}).optimize()\n",
    "        print(\"\\tObj LSHADE :  \", result_lshade.fun)\n",
    "        result_nlshadersp = NLSHADE_RSP (func.evaluate, bounds, data=None, x0=None, population_size=0, \n",
    "                            maxevals=Nmaxeval, callback=None, seed=None, memory_size=20*dimension, archive_size_ratio=2.1).optimize()\n",
    "        print(\"\\tObj NLSHADE RSP :  \", result_nlshadersp.fun)\n",
    "        #result_j20 = j2020(func.evaluate, bounds, data=None,  x0=None, populationSize=0, maxevals=Nmaxeval ).optimize()\n",
    "        #print(\"\\tObj j20 :  \", result_j20.fun)\n",
    "\n",
    "\n",
    "        result[\"ARRDE\"] = result_arrde.fun\n",
    "        result[\"LSRTDE\"] = result_lsrtde.fun\n",
    "        result[\"LSHADE\"] = result_lshade.fun\n",
    "        result[\"NLSHADE_RSP\"] = result_nlshadersp.fun\n",
    "        #result[\"j2020\"] = result_j20.fun\n",
    "\n",
    "        results.append(result)\n",
    "        print(\"\")\n",
    "        del func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict= {}\n",
    "algoRes = {\"NLSHADE_RSP\" : [],  \"ARRDE\":[], \"LSHADE\": [], \"LSRTDE\":[] }\n",
    "\n",
    "for algo in algoRes.keys() :\n",
    "    for num in [3, 4 ] : \n",
    "        ar = []\n",
    "        for res in results : \n",
    "            if res[\"Function_number\"]== num : ar.append(res[algo])\n",
    "        algoRes[algo].append(ar)\n",
    "\n",
    "       \n",
    "print(algoRes)\n",
    "\n",
    "algoResFinal = {}\n",
    "for algo, mat in algoRes.items() : algoResFinal[algo] = np.array(mat)\n",
    "dfarr = {}\n",
    "dfarr_test = {}\n",
    "for algo, mat in algoResFinal.items() : \n",
    "    np.savetxt(algo+\"_cec2011_3.txt\", mat.T )\n",
    "    res = []\n",
    "    res_test = []\n",
    "    for i, num in enumerate([3,4 ]) : \n",
    "        res_test.append(MWUT(algoResFinal[\"ARRDE\"][i], mat[i]))\n",
    "        res.append(np.mean(mat[i]))\n",
    "    dfarr_test[algo] = res_test\n",
    "    dfarr[algo] = res\n",
    "\n",
    "df = pd.DataFrame(dfarr)\n",
    "display(df)\n",
    "\n",
    "df_test = pd.DataFrame(dfarr_test)\n",
    "display(df_test)\n",
    "\n",
    "for algo in df_test.columns : \n",
    "    print(algo, \" : \", np.mean(df_test[algo]))\n",
    "\n",
    "    #print(\"Full results for function \"+str(num) +\":\\n\\t\", full_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate CEC Problem and Repeat for N times using multithreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionEvaluator:\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "        self.n_calls = 0\n",
    "\n",
    "    def __call__(self, X):\n",
    "        self.n_calls += 1\n",
    "        ret = self.func(np.array([X]))[0]\n",
    "        #print(X.shape, ret.shape)\n",
    "        return ret\n",
    "    \n",
    "class VectorizedEvaluator : \n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "        self.n_calls = 0\n",
    "\n",
    "    def __call__(self, X):\n",
    "        self.n_calls += X.shape[0]\n",
    "        ret = self.func(np.array(X))\n",
    "        return ret\n",
    "    \n",
    "class PyminionFunc : \n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "        self.n_calls = 0\n",
    "\n",
    "    def __call__(self, X, data=None):\n",
    "        X= np.array(X)\n",
    "        self.n_calls += X.shape[0]\n",
    "        return  self.func(X)\n",
    "    \n",
    "class VectorizedEvaluatorDE : \n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "        self.n_calls = 0\n",
    "\n",
    "    def __call__(self, X):\n",
    "        X = np.array(X).T\n",
    "        self.n_calls += X.shape[0]\n",
    "        return self.func(X)\n",
    "\n",
    "goptimum_cec22 = {\n",
    "    1 : 300, 2: 400, 3: 600, 4: 800, 5:900, 6:1800, 7:2000, 8:2200, 9:2300, 10: 2400, 11:2600, 12: 2700\n",
    "}\n",
    "goptimum_cec20 = {\n",
    "    1 : 100, 2: 1100, 3: 700, 4: 1900, 5:1700, 6:1600, 7:2100, 8:2200, 9:2400, 10: 2500\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global results variable\n",
    "results = []\n",
    "results_lock = threading.Lock()\n",
    "\n",
    "def test_optimization_threadsafe(func, bounds, dimension, func_name, Nmaxeval):\n",
    "    global results\n",
    "    result = {}\n",
    "    result['Dimensions'] = dimension\n",
    "    result['Function'] = func_name\n",
    "    # Initialize bounds\n",
    "    bounds_list = [bounds] * dimension\n",
    "    # Create wrapped function evaluator\n",
    "    evaluator = FunctionEvaluator(func)\n",
    "    vecEvaluator = VectorizedEvaluator(func)\n",
    "    vecEvaluatorDE = VectorizedEvaluatorDE(func)\n",
    "    pyminionFunc = PyminionFunc(func)\n",
    "    popsize= int(np.ceil((np.log10(Nmaxeval))**2.0+dimension/2.0))\n",
    "\n",
    "     #----------------------------------------------------------------#\n",
    "    options_LSHADE= {\n",
    "        \"memory_size\": 6, \n",
    "        \"archive_size_ratio\": 2.6, \n",
    "        \"population_reduction\" : True, \n",
    "        \"reduction_strategy\": \"linear\",\n",
    "        \"minimum_population_size\": 4, \n",
    "    }\n",
    "    \n",
    "    options_JADE =  {\n",
    "        \"mutation_strategy\": \"current_to_pbest_A1_1bin\",\n",
    "        \"archive_size_ratio\": 1.0, \n",
    "        \"population_reduction\" : True, \n",
    "        \"reduction_strategy\": \"linear\",\n",
    "        \"minimum_population_size\": dimension, \n",
    "        \"c\" : 0.1,\n",
    "    }\n",
    "\n",
    "    #pyminionFunc.n_calls =0\n",
    "    #jade = JADE (pyminionFunc, bounds_list, options=options_JADE, data=None, x0=None, population_size=0, \n",
    "    #                 maxevals=Nmaxeval, tol=0.0, callback=None, boundStrategy=\"reflect-random\", seed=None)\n",
    "    #res = jade.optimize()\n",
    "    #result['JADE'] = res.fun\n",
    "    \n",
    "    \n",
    "    #pyminionFunc.n_calls =0\n",
    "    lshade = LSHADE (pyminionFunc, bounds_list, options=options_LSHADE, data=None, x0=None, population_size=0, \n",
    "                     maxevals=Nmaxeval, tol=0.0, callback=None, boundStrategy=\"reflect-random\", seed=None)\n",
    "    res = lshade.optimize()\n",
    "    result['LSHADE'] = res.fun\n",
    "    #print(pyminionFunc.n_calls)\n",
    "    #----------------------------------------------------------------#\n",
    "\n",
    "    \n",
    "    #print(pyminionFunc.n_calls)\n",
    "    #----------------------------------------------------------------#\n",
    "\n",
    "     #----------------------------------------------------------------#\n",
    "    pyminionFunc.n_calls =0\n",
    "    lshade_rsp = NLSHADE_RSP (pyminionFunc, bounds_list, data=None, x0=None, population_size=0, \n",
    "                     maxevals=Nmaxeval, callback=None, seed=None, memory_size=20*dimension, archive_size_ratio=2.1)\n",
    "    res = lshade_rsp.optimize()\n",
    "    result['NLSHADE_RSP'] = res.fun\n",
    "    #print(pyminionFunc.n_calls)\n",
    "    #----------------------------------------------------------------#\n",
    "\n",
    "     #----------------------------------------------------------------#\n",
    "    pyminionFunc.n_calls =0\n",
    "    j20 = j2020 (pyminionFunc, bounds_list, data=None, x0=None,  \n",
    "                     maxevals=Nmaxeval, callback=None, seed=None, populationSize=0)\n",
    "    res = j20.optimize()\n",
    "    result['j2020'] = res.fun\n",
    "    #print(pyminionFunc.n_calls)\n",
    "    #----------------------------------------------------------------#\n",
    "\n",
    "     #----------------------------------------------------------------#\n",
    "    pyminionFunc.n_calls =0\n",
    "    lsrtde =LSRTDE (pyminionFunc, bounds_list, data=None, x0=None,  \n",
    "                     maxevals=Nmaxeval, callback=None, seed=None, populationSize=0)\n",
    "    res = lsrtde.optimize()\n",
    "    result['LSRTDE'] = res.fun\n",
    "    #print(pyminionFunc.n_calls)\n",
    "    #----------------------------------------------------------------#\n",
    "\n",
    "    #----------------------------------------------------------------\n",
    "    \n",
    "    pyminionFunc.n_calls=0\n",
    "    arrde = ARRDE (pyminionFunc, bounds_list, data=None, x0=None, population_size=0, \n",
    "                       maxevals=Nmaxeval, tol=0., callback=None, boundStrategy=\"reflect-random\", seed=None)\n",
    "    res = arrde.optimize()\n",
    "    result['ARRDE'] = res.fun\n",
    "    #print(pyminionFunc.n_calls)\n",
    "    #----------------------------------------------------------------#\n",
    "\n",
    "    #Differential Evolution (DE)\n",
    "    #vecEvaluatorDE.n_calls = 0\n",
    "    #de_result = differential_evolution(vecEvaluatorDE, bounds_list, popsize=3, strategy='best1bin',\n",
    "    #                                     maxiter=int(Nmaxeval/(3*dimension)), vectorized=True, updating=\"deferred\", disp=False,polish=False)\n",
    "    #result['Scipy DE'] = de_result.fun\n",
    "\n",
    "    with results_lock:\n",
    "        results.append(result)\n",
    "    print(result)\n",
    "\n",
    "Nmaxeval = 20000\n",
    "dimension = 20\n",
    "\n",
    "def run_test_optimization(j, dim):\n",
    "    cec_func = CEC2020Functions(function_number=j, dimension=dim)\n",
    "    test_optimization_threadsafe(cec_func, (-100, 100), dim, \"func_\" + str(j), Nmaxeval)\n",
    "\n",
    "\n",
    "func_numbers = [1,2,3,4,5,6,7, 8, 9,10, 11, 12] #2022\n",
    "func_numbers = [1,2,3,4,5,6,7, 8, 9,10]\n",
    "#func_numbers = [ 2,5,11, 10]\n",
    "#func_numbers = [ 9, 10]\n",
    "#func_numbers= [2, 8, 10, 11]\n",
    "#func_numbers= range(20, 30)\n",
    "Nrepeat= 11\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
    "\n",
    "    futures = []\n",
    "    for k in range(Nrepeat):\n",
    "        for j in func_numbers:\n",
    "            futures.append(executor.submit(run_test_optimization, j, dimension))\n",
    "    concurrent.futures.wait(futures)\n",
    "    for f in futures: f.result()\n",
    "\n",
    "for num in func_numbers : \n",
    "    mydict= {}\n",
    "    #algoRes = {\"NLSHADE_RSP\" : [],  \"ARRDE\":[]}\n",
    "    algoRes = {\"NLSHADE_RSP\" : [],  \"ARRDE\":[], \"j2020\":[], \"LSHADE\": [], 'Scipy DE':[],\"LSRTDE\":[] }\n",
    "    #algoRes = {\"NLSHADE_RSP\" : [],  \"ARRDE\":[], \"j2020\":[]}\n",
    "    for res in list(results) : \n",
    "        for algo in algoRes.keys() : \n",
    "            if res['Function'] == \"func_\"+str(num) :\n",
    "                algoRes[algo].append(res[algo])\n",
    "\n",
    "    full_results= {}\n",
    "    for key, val in algoRes.items() : \n",
    "        error = np.abs(np.array(val)-goptimum_cec22[num])\n",
    "        #error = error/goptimum_cec20[num]\n",
    "        error = val\n",
    "        full_results[key] = (np.min(error), np.mean(error), np.std(error))\n",
    "\n",
    "    print(\"Full results for function \"+str(num) +\":\\n\\t\", full_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curve Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dimension=11\n",
    "# Step 1: Generate data points from a polynomial \n",
    "np.random.seed(8)  # For reproducibility\n",
    "\n",
    "# True coefficients of the polynomial (degree 10)\n",
    "true_coefficients = [np.random.uniform(-1.0, 1.0)*1.0**i for i in range(dimension)]  # Random coefficients for the polynomial\n",
    "print(true_coefficients)\n",
    "\n",
    "# Generate 50 data points\n",
    "x_data = np.linspace(0.0, 1, dimension+50)\n",
    "y_data = (np.polyval(true_coefficients, x_data))\n",
    "\n",
    "# Step 2: Define the polynomial model\n",
    "def polynomial_model(x, coefficients):\n",
    "    \"\"\"Given x and coefficients, return the polynomial value.\"\"\"\n",
    "    return (np.polyval(coefficients, x))\n",
    "\n",
    "# Step 3: Define the objective function to minimize\n",
    "def objective_function(coefficients, x, y):\n",
    "    \"\"\"Objective function for optimization: Sum of squared errors.\"\"\"\n",
    "    y_pred = polynomial_model(x, coefficients)\n",
    "    return np.mean((y - y_pred)**2)\n",
    "\n",
    "def objective_function_vect(coefficients, data) : \n",
    "    ret = []\n",
    "    for coeff in coefficients : \n",
    "        ret.append(objective_function(coeff, x_data, y_data))\n",
    "    return ret\n",
    "\n",
    "bounds= [(-10, 10)]*dimension\n",
    "Nmaxeval= 50000  #1000*dimension\n",
    "\n",
    "# Optimize the coefficients using Nelder-Mead\n",
    "#result = opt.minimize(objective_function, np.ones(dimension), args=(x_data, y_data), method='Nelder-Mead', options={\"maxfev\":Nmaxeval, \"adaptive\":True }  ) \n",
    "\n",
    "result_arrde = ARRDE(objective_function_vect, bounds, data=None,  x0=None, population_size=0, maxevals=int(1.0*Nmaxeval), tol=0.0, boundStrategy=\"reflect-random\").optimize()\n",
    "#result_arrde = opt.minimize(objective_function, result_arrde.x, args=(x_data, y_data), method='Nelder-Mead', options={\"maxfev\":int(0.05*Nmaxeval), \"adaptive\":True }  ) \n",
    "\n",
    "result_lsrtde = LSRTDE(objective_function_vect, bounds, data=None,  x0=None, populationSize=0, maxevals=Nmaxeval ).optimize()\n",
    "result_lshade = LSHADE(objective_function_vect, bounds, data=None,  x0=None, population_size=0, maxevals=Nmaxeval, options= {}).optimize()\n",
    "result_nlshadersp = NLSHADE_RSP (objective_function_vect, bounds, data=None, x0=None, population_size=0, \n",
    "                     maxevals=Nmaxeval, callback=None, seed=None, memory_size=20*dimension, archive_size_ratio=2.1).optimize()\n",
    "result_j20 = j2020(objective_function_vect, bounds, data=None,  x0=None, populationSize=0, maxevals=Nmaxeval ).optimize()\n",
    "#result_de = differential_evolution(objective_function, bounds, args=(x_data, y_data), popsize=3, strategy='best1exp',\n",
    "#                                         maxiter=int(Nmaxeval/(3*dimension)), vectorized=False, disp=False,polish=False)\n",
    "\n",
    "# Step 5: Extract the fitted coefficients\n",
    "\n",
    "#fitted_coefficients_nm = result.x\n",
    "fitted_coefficients_arrde = result_arrde.x\n",
    "fitted_coefficients_lsrtde = result_lsrtde.x\n",
    "fitted_coefficients_nlshade = result_nlshadersp.x\n",
    "fitted_coefficients_j20= result_j20.x\n",
    "#fitted_coefficients_de= result_de.x\n",
    "fitted_coefficients_lshade= result_lshade.x\n",
    "\n",
    "# Step 6: Plot the results\n",
    "plt.scatter(x_data, y_data, label='Data Points')\n",
    "#plt.plot(x_data, np.polyval(true_coefficients, x_data), 'r-', label='True Polynomial')\n",
    "#plt.plot(x_data, np.polyval(fitted_coefficients_nm, x_data), 'g--', label='Fitted nm')\n",
    "plt.plot(x_data, polynomial_model(x_data, fitted_coefficients_lsrtde, ), 'b--', label='Fitted arrde')\n",
    "plt.plot(x_data, polynomial_model(x_data, fitted_coefficients_arrde, ), 'g--', label='Fitted LSRTDE')\n",
    "plt.plot(x_data, polynomial_model(x_data, fitted_coefficients_nlshade, ), 'black', label='Fitted NLSHADE RSP')\n",
    "plt.plot(x_data, polynomial_model(x_data, fitted_coefficients_j20, ), 'yellow', label='Fitted j20')\n",
    "plt.legend()\n",
    "plt.title('Polynomial Fit using Nelder-Mead')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()\n",
    "\n",
    "# Display the true and fitted coefficients\n",
    "#print(\"True coefficients:    \", true_coefficients)\n",
    "#print(\"Fitted coefficients NM :  \", fitted_coefficients_nm)\n",
    "#print(\"Fitted coefficients ARRDE :  \", fitted_coefficients_arrde)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "#print(\"Obj NM :  \",result.fun)\n",
    "print(\"Obj ARRDE :  \", result_arrde.fun)\n",
    "print(\"Obj LSRTDE :  \", result_lsrtde.fun)\n",
    "print(\"Obj NLSHADE RSP :  \", result_nlshadersp.fun)\n",
    "print(\"Obj lshade:  \", result_lshade.fun)\n",
    "print(\"Obj j20 :  \", result_j20.fun)\n",
    "#print(\"Obj de :  \", result_de.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit RBF basis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "np.random.seed(5)  # For reproducibility\n",
    "num_rbf = 100\n",
    "true_centers = 10*(-1+2*np.random.random(num_rbf))\n",
    "true_widths = np.random.rand(num_rbf) + 1.0  # Widths (variances)\n",
    "true_coeffs = 2.0*np.random.rand(num_rbf)\n",
    "print(true_centers)\n",
    "print(true_widths)\n",
    "print(true_coeffs)\n",
    "dimension= num_rbf*3\n",
    "\n",
    "# Define a Gaussian RBF function\n",
    "def rbf(x, center, width):\n",
    "    \"\"\"Compute a Gaussian RBF value given x, center, and width.\"\"\"\n",
    "    return (1.0/2.0*np.pi*width**2)*np.exp(-((x - center) ** 2) / (2 * width ** 2))\n",
    "\n",
    "# Define the function as a sum of RBFs\n",
    "def rbf_sum(x, centers, widths, coeffs):\n",
    "    \"\"\"Sum of Gaussian RBFs.\"\"\"\n",
    "    result = np.zeros_like(x)\n",
    "    coeffs= np.array(coeffs)\n",
    "    norm_coeff = coeffs/np.sum(coeffs)\n",
    "    for i in range(len(centers)):\n",
    "        result += norm_coeff[i] * rbf(x, centers[i], widths[i])\n",
    "    return result\n",
    "\n",
    "\n",
    "# Generate 50 data points\n",
    "x_data = np.linspace(-20, 20,dimension+50)\n",
    "y_data = rbf_sum(x_data, true_centers, true_widths, true_coeffs)  # Add some noise\n",
    "\n",
    "\n",
    "# Step 2: Define the model for fitting\n",
    "def rbf_model(x, params):\n",
    "    \"\"\"RBF model with combined parameters (centers, widths, and coefficients).\"\"\"\n",
    "    num_rbf = len(params) // 3\n",
    "    centers = params[:num_rbf]\n",
    "    widths = params[num_rbf:2*num_rbf]\n",
    "    coeffs = params[2*num_rbf:]\n",
    "    return rbf_sum(x, centers, widths, coeffs)\n",
    "\n",
    "def rbf_data(params):\n",
    "    \"\"\"RBF model with combined parameters (centers, widths, and coefficients).\"\"\"\n",
    "    num_rbf = len(params) // 3\n",
    "    centers = params[:num_rbf]\n",
    "    widths = params[num_rbf:2*num_rbf]\n",
    "    coeffs = params[2*num_rbf:]\n",
    "    return rbf_sum(x_data, centers, widths, coeffs)\n",
    "\n",
    "# Step 3: Define the objective function to minimize\n",
    "def objective_function(params):\n",
    "    \"\"\"Objective function for optimization: Sum of squared errors.\"\"\"\n",
    "    y_pred = rbf_model(x_data, params)\n",
    "    return np.mean((y_data - y_pred) ** 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "executor = concurrent.futures.ThreadPoolExecutor(max_workers=4)\n",
    "def objective_function_vect(params, data) : \n",
    "    #ret = []\n",
    "    #for p in params : \n",
    "    #    ret.append(objective_function(p, x_data, y_data))\n",
    "    ret = list(executor.map(objective_function, params))\n",
    "    return ret\n",
    "\n",
    "\n",
    "initial_guess = np.concatenate([\n",
    "    np.linspace(-100, 100, num_rbf),  # Initial guess for centers\n",
    "    np.ones(num_rbf),  # Initial guess for widths\n",
    "    np.zeros(num_rbf)  # Initial guess for coefficients\n",
    "])\n",
    "\n",
    "\n",
    "bounds= [(-10, 10)]*dimension\n",
    "Nmaxeval=50000#5000*dimension\n",
    "\n",
    "# Optimize the coefficients using Nelder-Mead\n",
    "\n",
    "#result = opt.minimize(objective_function, initial_guess, args=(), method='Nelder-Mead', options={\"maxfev\":Nmaxeval, \"adaptive\":True }  ) \n",
    "#print(\"SIMPLEX done\")\n",
    "result_arrde = ARRDE(objective_function_vect, bounds, data=None,  x0=None, population_size=0, maxevals=Nmaxeval, tol=0.0 ).optimize()\n",
    "print(\"ARRDE done\")\n",
    "result_lsrtde = LSRTDE(objective_function_vect, bounds, data=None,  x0=None, populationSize=0, maxevals=Nmaxeval ).optimize()\n",
    "print(\"LSRTDE done\")\n",
    "result_lshade = LSHADE(objective_function_vect, bounds, data=None,  x0=None, population_size=0, maxevals=Nmaxeval, options= {}).optimize()\n",
    "print(\"LSHADE done\")\n",
    "result_nlshadersp = NLSHADE_RSP (objective_function_vect, bounds, data=None, x0=None, population_size=0, \n",
    "                     maxevals=Nmaxeval, callback=None, seed=None, memory_size=20*dimension, archive_size_ratio=2.1).optimize()\n",
    "print(\"RSP done\")\n",
    "result_j20 = j2020(objective_function_vect, bounds, data=None,  x0=None, populationSize=0, maxevals=Nmaxeval ).optimize()\n",
    "print(\"j20 done\")\n",
    "#result_de = differential_evolution(objective_function, bounds, args=(x_data, y_data), popsize=1, strategy='best1bin',\n",
    "#                                         maxiter=int(Nmaxeval/(3*dimension)), vectorized=False, disp=False,polish=False)\n",
    "#print(\"DE done\")\n",
    "\n",
    "plt.plot(x_data, y_data, label=\"data\", color=\"black\")\n",
    "plt.plot(x_data, rbf_data(result_arrde.x), label=\"ARRDE\")\n",
    "plt.plot(x_data, rbf_data(result_lsrtde.x), label=\"LSRTDE\")\n",
    "plt.plot(x_data, rbf_data(result_nlshadersp.x), label=\"NLSHADE RSP\")\n",
    "#plt.plot(x_data, rbf_data(result_j20.x), label=\"j2020\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "#\n",
    "#print(\"Obj NM :  \",result.fun)\n",
    "print(\"Obj ARRDE :  \", result_arrde.fun)\n",
    "print(\"Obj LSRTDE :  \", result_lsrtde.fun)\n",
    "print(\"Obj NLSHADE RSP :  \", result_nlshadersp.fun)\n",
    "print(\"Obj lshade:  \", result_lshade.fun)\n",
    "#print(\"Obj j20 :  \", result_j20.fun)\n",
    "#print(\"Obj de :  \", result_de.fun)\n",
    "\n",
    "executor.shutdown()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class CT18PDFs : \n",
    "    def __init__(self) : \n",
    "        self.parameters = {\n",
    "            \"uv_0\" : 3.385, \"uv_1\" : 0.763, \"uv_2\" : 3.036, \"uv_3\" : 1.502, \"uv_4\" : -0.147,\"uv_5\" : 1.671, \"uv_6\" : 0.,\n",
    "            \"dv_0\" : 0.490, \"dv_1\" : 0.763, \"dv_2\" : 3.036, \"dv_3\" : 2.615, \"dv_4\" : 1.828,\"dv_5\" : 2.721, \"dv_6\" : 0., \n",
    "            \"g_0\" : 2.690, \"g_1\" : 0.531, \"g_2\" : 3.148, \"g_3\" : 3.032, \"g_4\" : -1.705, \"g_5\" : 1.354, \n",
    "            \"ubar_0\" : 0.414, \"ubar_1\" : -0.022, \"ubar_2\" : 7.737, \"ubar_3\" : 4.0, \"ubar_4\" : 0.618,\"ubar_5\" : 0.195, \"ubar_6\" : 0.871, \"ubar_7\" : 0.267,\"ubar_8\" : 0.733,\n",
    "            \"dbar_0\" : 0.414, \"dbar_1\" : -0.022, \"dbar_2\" : 7.737, \"dbar_3\" : 4.0, \"dbar_4\" : 0.292,\"dbar_5\" : 0.647, \"dbar_6\" : 0.474, \"dbar_7\" : 0.741,\"dbar_8\" :1.0,\n",
    "            \"s_0\" : 0.288, \"s_1\" : -0.022, \"s_2\" : 10.31, \"s_3\" : 4.0, \"s_4\" : 0.466,\"s_5\" : 0.466, \"s_6\" : 0.225, \"s_7\" : 0.225,\"s_8\" : 1.0,\n",
    "        }\n",
    "        self.xlist = np.linspace(1e-3, 0.8, 100)\n",
    "        self.paramNames = list(self.parameters.keys())\n",
    "        self.originalData = self.getData()\n",
    "\n",
    "    def uv(self, x) : \n",
    "        a0 = self.parameters[\"uv_0\"]\n",
    "        a1 = self.parameters[\"uv_1\"]\n",
    "        a2 = self.parameters[\"uv_2\"]\n",
    "        a3 = self.parameters[\"uv_3\"]\n",
    "        a4 = self.parameters[\"uv_4\"]\n",
    "        a5 = self.parameters[\"uv_5\"]\n",
    "        a6 = self.parameters[\"uv_6\"]\n",
    "        y= np.sqrt(x)\n",
    "        P = np.sinh(a3)*(1-y)**4 + np.sinh(a4) *4*y*(1-y)**3 + np.sinh(a5) *6*y**2*(1-y)**2 + np.sinh(a6) *4*y**3*(1-y) + y**4\n",
    "        return a0 * x**(a1-1)*(1-x)**a2*P\n",
    "    \n",
    "    def dv(self, x) : \n",
    "        a0 = self.parameters[\"dv_0\"]\n",
    "        a1 = self.parameters[\"dv_1\"]\n",
    "        a2 = self.parameters[\"dv_2\"]\n",
    "        a3 = self.parameters[\"dv_3\"]\n",
    "        a4 = self.parameters[\"dv_4\"]\n",
    "        a5 = self.parameters[\"dv_5\"]\n",
    "        a6 = self.parameters[\"dv_6\"]\n",
    "        y= np.sqrt(x)\n",
    "        P = np.sinh(a3)*(1-y)**4 + np.sinh(a4) *4*y*(1-y)**3 + np.sinh(a5) *6*y**2*(1-y)**2 + np.sinh(a6) *4*y**3*(1-y) + y**4\n",
    "        return a0 * x**(a1-1)*(1-x)**a2*P\n",
    "    \n",
    "    def g(self, x) : \n",
    "        a0 = self.parameters[\"g_0\"]\n",
    "        a1 = self.parameters[\"g_1\"]\n",
    "        a2 = self.parameters[\"g_2\"]\n",
    "        a3 = self.parameters[\"g_3\"]\n",
    "        a4 = self.parameters[\"g_4\"]\n",
    "        a5 = self.parameters[\"g_5\"]\n",
    "        y= np.sqrt(x)\n",
    "        P = np.sinh(a3)*(1-y)**3 + np.sinh(a4) *3*y*(1-y)**2 + np.sinh(a5) *3*y**2*(1-y)  + y**3\n",
    "        return a0 * x**(a1-1)*(1-x)**a2*P\n",
    "    \n",
    "    def ubar(self, x) : \n",
    "        a0 = self.parameters[\"ubar_0\"]\n",
    "        a1 = self.parameters[\"ubar_1\"]\n",
    "        a2 = self.parameters[\"ubar_2\"]\n",
    "        a3 = self.parameters[\"ubar_3\"]\n",
    "        a4 = self.parameters[\"ubar_4\"]\n",
    "        a5 = self.parameters[\"ubar_5\"]\n",
    "        a6 = self.parameters[\"ubar_6\"]\n",
    "        a7 = self.parameters[\"ubar_7\"]\n",
    "        a8 = self.parameters[\"ubar_8\"]\n",
    "        y= 1-(1-np.sqrt(x))**a3\n",
    "        P = (1-y)**5 + a4 * 5*y*(1-y)**4 + a5 * 10*y**2*(1-y)**3 +  a6 * 10*y**3*(1-y)**2 +  a7 * 5*y**4*(1-y)+  a8 * 5*y**5\n",
    "        return a0 * x**(a1-1)*(1-x)**a2*P\n",
    "    \n",
    "    def dbar(self, x) : \n",
    "        a0 = self.parameters[\"dbar_0\"]\n",
    "        a1 = self.parameters[\"dbar_1\"]\n",
    "        a2 = self.parameters[\"dbar_2\"]\n",
    "        a3 = self.parameters[\"dbar_3\"]\n",
    "        a4 = self.parameters[\"dbar_4\"]\n",
    "        a5 = self.parameters[\"dbar_5\"]\n",
    "        a6 = self.parameters[\"dbar_6\"]\n",
    "        a7 = self.parameters[\"dbar_7\"]\n",
    "        a8 = self.parameters[\"dbar_8\"]\n",
    "        y= 1-(1-np.sqrt(x))**a3\n",
    "        P = (1-y)**5 + a4 * 5*y*(1-y)**4 + a5 * 10*y**2*(1-y)**3 +  a6 * 10*y**3*(1-y)**2 +  a7 * 5*y**4*(1-y)+  a8 * 5*y**5\n",
    "        return a0 * x**(a1-1)*(1-x)**a2*P\n",
    "    \n",
    "    def s(self, x) : \n",
    "        a0 = self.parameters[\"s_0\"]\n",
    "        a1 = self.parameters[\"s_1\"]\n",
    "        a2 = self.parameters[\"s_2\"]\n",
    "        a3 = self.parameters[\"s_3\"]\n",
    "        a4 = self.parameters[\"s_4\"]\n",
    "        a5 = self.parameters[\"s_5\"]\n",
    "        a6 = self.parameters[\"s_6\"]\n",
    "        a7 = self.parameters[\"s_7\"]\n",
    "        a8 = self.parameters[\"s_8\"]\n",
    "        y= 1-(1-np.sqrt(x))**a3\n",
    "        P = (1-y)**5 + a4 * 5*y*(1-y)**4 + a5 * 10*y**2*(1-y)**3 +  a6 * 10*y**3*(1-y)**2 +  a7 * 5*y**4*(1-y)+  a8 * 5*y**5\n",
    "        return a0 * x**(a1-1)*(1-x)**a2*P\n",
    "    \n",
    "    def u(self, x) : return self.uv(x)+self.ubar(x)\n",
    "    def d(self, x) : return self.dv(x)+self.dbar(x) \n",
    "\n",
    "    def setParameter(self, pars) : \n",
    "        assert(len(pars)==len(self.parameters)) \n",
    "        self.parameters= dict(zip(self.paramNames, pars))\n",
    "\n",
    "    def getData(self) : \n",
    "        x= self.xlist\n",
    "        return [ x*self.u(self.xlist), x*self.ubar(self.xlist), x*self.d(self.xlist), x*self.dbar(self.xlist), x*self.g(self.xlist), x*self.s(self.xlist)]\n",
    "    \n",
    "    def chi2(self, params) : \n",
    "        self.setParameter(params) \n",
    "        data = self.getData() \n",
    "        ret =0\n",
    "        for do, d in zip(self.originalData, data) : \n",
    "            ret = ret + np.sum((do-d)**2)\n",
    "        return ret \n",
    "    \n",
    "    def chi2_vect(self, params, data=None) : \n",
    "        return [self.chi2(p) for p in params ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct18 = CT18PDFs() \n",
    "data = ct18.getData() \n",
    "plt.plot(ct18.xlist, data[0], label=\"u\")\n",
    "plt.plot(ct18.xlist, data[1],  label=\"ubar\")#\n",
    "plt.plot(ct18.xlist, data[2],  label=\"d\")\n",
    "plt.plot(ct18.xlist, data[3],  label=\"dbar\")\n",
    "plt.plot(ct18.xlist, data[4],  label=\"g\")\n",
    "plt.plot(ct18.xlist, data[5],  label=\"s\")\n",
    "#plt.xscale(\"log\")\n",
    "plt.legend()\n",
    "plt.xlim(0.1, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 47\n",
    "print(\"Dimension : \", dimension)\n",
    "bounds= [(-10, 10)]*dimension\n",
    "Nmaxeval=50000\n",
    "\n",
    "# Optimize the coefficients using Nelder-Mead\n",
    "\n",
    "results = []\n",
    "for i in range(11) :\n",
    "    result = {}\n",
    "    #result = opt.minimize(objective_function, initial_guess, args=(), method='Nelder-Mead', options={\"maxfev\":Nmaxeval, \"adaptive\":True }  ) \n",
    "    #print(\"SIMPLEX done\")\n",
    "    result_arrde = ARRDE(ct18.chi2_vect, bounds, data=None,  x0=None, population_size=0, maxevals=Nmaxeval, tol=0.0 ).optimize()\n",
    "    print(\"\\tObj ARRDE :  \", result_arrde.fun)\n",
    "    result[\"ARRDE\"] = result_arrde.fun\n",
    "\n",
    "    result_lsrtde = LSRTDE(ct18.chi2_vect, bounds, data=None,  x0=None, populationSize=0, maxevals=Nmaxeval ).optimize()\n",
    "    print(\"\\tObj LSRTDE :  \", result_lsrtde.fun)\n",
    "    result[\"LSRTDE\"] = result_lsrtde.fun\n",
    "\n",
    "    result_lshade = LSHADE(ct18.chi2_vect, bounds, data=None,  x0=None, population_size=0, maxevals=Nmaxeval, options= {}).optimize()\n",
    "    print(\"\\tObj LSHADE :  \", result_lshade.fun)\n",
    "    result[\"LSHADE\"] = result_lshade.fun\n",
    "\n",
    "    result_nlshadersp = NLSHADE_RSP (ct18.chi2_vect, bounds, data=None, x0=None, population_size=0, \n",
    "                        maxevals=Nmaxeval, callback=None, seed=None, memory_size=20*dimension, archive_size_ratio=2.1).optimize()\n",
    "    print(\"\\tObj NLSHADE RSP :  \", result_nlshadersp.fun)\n",
    "    result[\"NLSHADE_RSP\"] = result_nlshadersp.fun\n",
    "\n",
    "    result_j20 = j2020(ct18.chi2_vect, bounds, data=None,  x0=None, populationSize=0, maxevals=Nmaxeval ).optimize()\n",
    "    print(\"\\tObj j2020 :  \", result_j20.fun)\n",
    "    result[\"j2020\"] = result_j20.fun\n",
    "    #result_de = differential_evolution(objective_function, bounds, args=(x_data, y_data), popsize=1, strategy='best1bin',\n",
    "    #                                         maxiter=int(Nmaxeval/(3*dimension)), vectorized=False, disp=False,polish=False)\n",
    "    print(\"\")\n",
    "    results.append(result)\n",
    "\n",
    "    \n",
    "algoRes = {\"ARRDE\" : [], \"LSRTDE\" :[], \"NLSHADE_RSP\" : [], \"j2020\" : [] }\n",
    "for algo in algoRes.keys() : \n",
    "    for res in results : algoRes[algo].append(res[algo])\n",
    "\n",
    "for algo in algoRes : \n",
    "    print (algo, \" : \", MWUT(algoRes[\"ARRDE\"], algoRes[algo]), np.mean( algoRes[algo]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "algoRes = {\"ARRDE\" : [], \"LSRTDE\" :[], \"LSHADE\": [], \"NLSHADE_RSP\" : [], \"j2020\" : [] }\n",
    "for algo in algoRes.keys() : \n",
    "    for res in results : algoRes[algo].append(res[algo])\n",
    "\n",
    "for algo in algoRes : \n",
    "    print (algo, \" : \", MWUT(algoRes[\"ARRDE\"], algoRes[algo]), np.mean( algoRes[algo]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "print(torch.backends.mps.is_available())\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "#device =torch.device(\"cpu\")\n",
    "print(\"Device : \", device)\n",
    "\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(SimpleNN, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        \n",
    "        layers.append(nn.Linear(input_size, hidden_size))\n",
    "        layers.append(nn.Tanh())\n",
    "        \n",
    "        for _ in range(num_layers - 1):\n",
    "            layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "            layers.append(nn.Tanh())\n",
    "        \n",
    "        layers.append(nn.Linear(hidden_size, output_size))        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def optimize_adam(num_epochs, batch_size=25):\n",
    "    model = SimpleNN(input_size, hidden_size, output_size, num_layers).to(device)\n",
    "    optimizer_adam = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    x_tensor_device = x_tensor.to(device)\n",
    "    y_tensor_device = y_tensor.to(device)\n",
    "\n",
    "    # Create a DataLoader for batching\n",
    "    dataset = TensorDataset(x_tensor_device, y_tensor_device)\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    loss_history = []\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer_adam.zero_grad()  # Clear gradients\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(batch_x).squeeze(-1)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, batch_y.squeeze(-1))\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer_adam.step()\n",
    "        \n",
    "        # Store the epoch loss\n",
    "        loss_history.append(epoch_loss / len(train_loader))\n",
    "        \n",
    "        # if (epoch+1) % 100 == 0:\n",
    "        #     print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss / len(train_loader):.4f}')\n",
    "    \n",
    "    # Final loss calculation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(x_tensor_device).squeeze(-1)\n",
    "        loss = criterion(outputs, y_tensor_device.squeeze(-1))\n",
    "    \n",
    "    return loss.cpu().item(), model\n",
    "\n",
    "\n",
    "def objective_function_nn(params, x, y):\n",
    "    # Set the model parameters from the optimization algorithm\n",
    "    start = 0\n",
    "    for i, param in enumerate(model.parameters()):\n",
    "        size = param.numel()\n",
    "        param.data = torch.tensor(params[start:start+size], dtype=torch.float32).reshape(param.size())\n",
    "        start += size\n",
    "\n",
    "    # Forward pass\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    outputs = model(x).squeeze(-1)\n",
    "\n",
    "    # Calculate loss (MSE)\n",
    "    loss = criterion(outputs,y.squeeze(-1)).item()\n",
    "    return loss\n",
    "\n",
    "def objective_function_vect_nn(coefficients, data):\n",
    "    ret = []\n",
    "    for coeff in coefficients:\n",
    "        ret.append(objective_function_nn(coeff, x_tensor, y_tensor))\n",
    "    return ret\n",
    "\n",
    "def optimize_nn_de(mode, epochs) :\n",
    "    global model\n",
    "\n",
    "    model = SimpleNN(input_size, hidden_size, output_size, num_layers)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    #print(f\"Total number of parameters: {total_params}\")\n",
    "\n",
    "    Nmaxeval=epochs\n",
    "    bounds_nn = [(-10, 10)] * total_params\n",
    "    if mode == \"ARRDE\" :\n",
    "        result_nn = ARRDE(objective_function_vect_nn, bounds_nn, data=None, x0=None, population_size=0, maxevals=int(1.0*Nmaxeval), tol=0.0).optimize()\n",
    "        # print(\"arrde done\")\n",
    "    elif mode == \"LSRTDE\" :\n",
    "        result_nn = LSRTDE(objective_function_vect_nn, bounds_nn, data=None,  x0=None, populationSize=0, maxevals=Nmaxeval ).optimize()\n",
    "        # print(\"lstrde done\")\n",
    "    elif mode == \"LSHADE\" :\n",
    "        result_nn = LSHADE(objective_function_vect_nn, bounds_nn, data=None,  x0=None, population_size=0, maxevals=Nmaxeval, options= {}).optimize()\n",
    "        # print(\"LSHADE done\")\n",
    "    elif mode == \"NLSHADE_RSP\" :\n",
    "        result_nn = NLSHADE_RSP(objective_function_vect_nn, bounds_nn, data=None, x0=None, population_size=0, maxevals=Nmaxeval, callback=None, seed=None, memory_size=20*dimension, archive_size_ratio=2.1).optimize()\n",
    "        # print(\"RSP done\")\n",
    "    elif mode == \"j2020\" :\n",
    "        result_nn = j2020(objective_function_vect_nn, bounds_nn, data=None,  x0=None, populationSize=0, maxevals=Nmaxeval ).optimize()\n",
    "        # print(\"j20 done\")\n",
    "    return result_nn.fun, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5)  # For reproducibility\n",
    "num_rbf = 100\n",
    "true_centers = 10*(-1+2*np.random.random(num_rbf))\n",
    "true_widths = np.random.rand(num_rbf) + 1.0  # Widths (variances)\n",
    "true_coeffs = 2.0*np.random.rand(num_rbf)\n",
    "#print(true_centers)\n",
    "#print(true_widths)\n",
    "#print(true_coeffs)\n",
    "dimension= num_rbf*3\n",
    "\n",
    "# Define a Gaussian RBF function\n",
    "def rbf(x, center, width):\n",
    "    \"\"\"Compute a Gaussian RBF value given x, center, and width.\"\"\"\n",
    "    return (1.0/2.0*np.pi*width**2)*np.exp(-((x - center) ** 2) / (2 * width ** 2))\n",
    "\n",
    "# Define the function as a sum of RBFs\n",
    "def rbf_sum(x, centers, widths, coeffs):\n",
    "    \"\"\"Sum of Gaussian RBFs.\"\"\"\n",
    "    result = np.zeros_like(x)\n",
    "    coeffs= np.array(coeffs)\n",
    "    norm_coeff = coeffs/np.sum(coeffs)\n",
    "    for i in range(len(centers)):\n",
    "        result += norm_coeff[i] * rbf(x, centers[i], widths[i])\n",
    "    return result\n",
    "\n",
    "\n",
    "x_data = np.linspace(-20, 20,dimension+50)\n",
    "y_data = rbf_sum(x_data, true_centers, true_widths, true_coeffs)  # Add some noise\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "x_tensor = torch.tensor(x_data, dtype=torch.float32).unsqueeze(1)  # (50, 1)\n",
    "y_tensor = torch.tensor(y_data, dtype=torch.float32).unsqueeze(1)  # (50, 1)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1\n",
    "hidden_sizes = [5, 10, 20]\n",
    "output_size = 1\n",
    "num_layerses = [1, 2]\n",
    "num_epochses = [50000]#, 100000, 150000]\n",
    "\n",
    "runs = 5\n",
    "\n",
    "log_file = \"optimization_log.txt\"\n",
    "\n",
    "with open(log_file, \"w\") as log:\n",
    "    for hidden_size, num_layers, num_epochs in itertools.product(hidden_sizes, num_layerses, num_epochses):\n",
    "        log_message = f\"Hidden Size: {hidden_size}, Number of Layers: {num_layers}, Number of Epochs: {num_epochs}\\n\"\n",
    "        print(log_message)\n",
    "        log.write(log_message)\n",
    "        log.flush()\n",
    "\n",
    "        model_ = SimpleNN(input_size, hidden_size, output_size, num_layers)\n",
    "        total_params = sum(p.numel() for p in model_.parameters())\n",
    "        print(f\"Total number of parameters: {total_params}\")\n",
    "        \"\"\"\n",
    "        adam_times = []\n",
    "        adam_mses = []\n",
    "\n",
    "        for _ in range(1):\n",
    "             # Measure time and MSE for Adam\n",
    "             start_time = time.time()\n",
    "             mse_adam, model_trained_adam = optimize_adam(10000, len(x_data))\n",
    "             adam_times.append(time.time() - start_time)\n",
    "             adam_mses.append(mse_adam)\n",
    "        \n",
    "        mean_adam_time = np.mean(adam_times)\n",
    "        mean_adam_mse = np.mean(adam_mses)\n",
    "        log_message = f\"Adam: Mean Time = {mean_adam_time:.4f} seconds, Mean MSE = {mean_adam_mse:.4f}\\n\"\n",
    "        print(log_message)\n",
    "        log.write(log_message)\n",
    "        log.flush()\n",
    "        \"\"\"\n",
    "        modes = [\"ARRDE\", \"LSRTDE\", \"LSHADE\", \"NLSHADE_RSP\", \"j2020\"]\n",
    "        for mode in modes :\n",
    "            de_mses = []\n",
    "            de_times = []\n",
    "            for _ in range(runs):\n",
    "                start_time = time.time()\n",
    "                mse_de, model_trained_de = optimize_nn_de(mode, num_epochs)\n",
    "                de_times.append(time.time() - start_time)\n",
    "                de_mses.append(mse_de)\n",
    "\n",
    "            mean_de_time = np.mean(de_times)    \n",
    "            mean_de_mse = np.mean(de_mses)\n",
    "            log_message = f\"{mode}: Mean Time = {mean_de_time:.4f} seconds, Mean MSE = {mean_de_mse:.4f}\\n\"\n",
    "            print(log_message)\n",
    "            log.write(log_message)\n",
    "            log.flush()\n",
    "\n",
    "        print(\"--------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Differential Veolution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a simple neural network\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 20)\n",
    "        self.fc3 = nn.Linear(20, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # Flatten the input tensor from (batch_size, 1, 28, 28) to (batch_size, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Function to train the model\n",
    "def train_model(optimizer, model, train_loader, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "    total_loss=0\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            \n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}\")\n",
    "\n",
    "\n",
    "class LOSS:\n",
    "    def __init__(self, train_loader, model, loss_fn):\n",
    "        \"\"\"\n",
    "        :param train_loader: PyTorch DataLoader for training data\n",
    "        :param model: A PyTorch model (e.g., SimpleNet)\n",
    "        :param loss_fn: Loss function (e.g., F.nll_loss)\n",
    "        \"\"\"\n",
    "        self.train_loader = train_loader\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "        self.iterator = iter(self.train_loader)\n",
    "        self.batchNums= len(train_loader)\n",
    "        print(\"Number of batches : \", len(train_loader))\n",
    "        self.end=False\n",
    "        self.totloss=0.0\n",
    "        model.train()\n",
    "        \n",
    "    def get_flat_params(self):\n",
    "        \"\"\"Flatten model parameters into a 1D numpy array.\"\"\"\n",
    "        params = []\n",
    "        for param in self.model.parameters():\n",
    "            params.append(param.data.cpu().numpy().ravel())\n",
    "        return np.concatenate(params)\n",
    "\n",
    "    def set_flat_params(self, flat_params):\n",
    "        \"\"\"Set model parameters from a flattened 1D numpy array.\"\"\"\n",
    "        pointer = 0\n",
    "        for param in self.model.parameters():\n",
    "            num_params = param.numel()\n",
    "            param.data = torch.tensor(flat_params[pointer:pointer + num_params]).view_as(param).to(self.device)\n",
    "            pointer += num_params\n",
    "\n",
    "    def get_data(self):\n",
    "        \"\"\"Fetch the next batch of data from the DataLoader.\"\"\"\n",
    "        try:\n",
    "            data, target = next(self.iterator)\n",
    "        except StopIteration:\n",
    "            self.iterator = iter(self.train_loader)\n",
    "            data, target = next(self.iterator)\n",
    "            self.end=True\n",
    "        return data, target\n",
    "\n",
    "    def loss(self, flat_params):\n",
    "        \"\"\"Compute the loss for the model.\"\"\"\n",
    "        self.set_flat_params(flat_params)\n",
    "        data, target = self.get_data()\n",
    "        data, target = data.to(self.device), target.to(self.device)\n",
    "        output = self.model(data)\n",
    "        loss = self.loss_fn(output, target).item()  # Correct call to .item()\n",
    "        \n",
    "        if (self.end) : \n",
    "            print(f\"Loss: {self.totloss / len(self.train_loader)}\")\n",
    "            self.end=False\n",
    "            self.totloss=0\n",
    "        self.totloss+=loss\n",
    "        return loss\n",
    "    \n",
    "    def loss_vect(self, pars, data=None) : \n",
    "        return [self.loss(p) for p in pars]\n",
    "\n",
    "\n",
    "# Load MNIST data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_data = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_data = Subset(train_data, range(1000))\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=len(train_data), shuffle=True)\n",
    "print(len(train_data))\n",
    "\n",
    "# Initialize model\n",
    "model = SimpleNet()\n",
    "# Count the total number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params}\")\n",
    "\n",
    "# Optimizers\n",
    "optimizer_sgd = optim.SGD(model.parameters(), lr=0.01)\n",
    "optimizer_adam = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# Training comparison\n",
    "print(\"Training with SGD:\")\n",
    "train_model(optimizer_sgd, model, train_loader, 500)\n",
    "\n",
    "print(\"\\nTraining with Adam:\")\n",
    "train_model(optimizer_adam, model, train_loader, 500)\n",
    "\n",
    "#print(\"\\nTraining with Custom Optimizer:\")\n",
    "#train_model(optimizer_custom, model, train_loader)\n",
    "\n",
    "obj = LOSS(train_loader, model, F.nll_loss)\n",
    "bounds=[(-0.05, 0.05)]*total_params\n",
    "result_arrde = ARRDE(obj.loss_vect, bounds, data=None,  x0=None, population_size=100, maxevals=5000, tol=0.0, boundStrategy=\"none\" ).optimize()\n",
    "print(\"\\tObj ARRDE :  \", result_arrde.fun)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
