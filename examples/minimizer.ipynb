{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from scipy.optimize import differential_evolution, minimize, dual_annealing\n",
    "import matplotlib.pyplot as plt\n",
    "import concurrent.futures\n",
    "import threading, multiprocessing\n",
    "\n",
    "import sys \n",
    "sys.path.append(\"../\")  \n",
    "import minionpy as mpy\n",
    "import minionpy.test_functions as mpytest\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimizing Basic Functions\n",
    "\n",
    "In this section, we minimize basic functions such as Sphere, Rosenbrock, and Rastrigin. The search space is shifted to prevent algorithms from converging near the origin, as some algorithms tend to favor that region.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sphere(x) : \n",
    "    x =np.asarray(x)-1\n",
    "    return 100+np.sum(x**2)\n",
    "\n",
    "def rosenbrock(x):\n",
    "    #if x[0]<-1 or x[0]>1 : print(x, \"bound violated\")\n",
    "    x = np.asarray(x)-5.0\n",
    "    return 100+np.sum(100 * (x[1:] - x[:-1]**2)**2 + (1 - x[:-1])**2)\n",
    "\n",
    "def rastrigin(x):\n",
    "    x = np.asarray(x)-1.0\n",
    "    A = 10\n",
    "    return 100+A * len(x) + np.sum(x**2 - A * np.cos(2 * np.pi * x))\n",
    "\n",
    "#remember that in minion, objective function must be vectorized. Suppose you want to \n",
    "func = rosenbrock\n",
    "def objective_function(X) : \n",
    "    \"\"\" \n",
    "    Here, X is a list of x, where x is an input vector. \n",
    "    \"\"\"\n",
    "    return [func(x) for x in X] \n",
    "\n",
    "#Now minimize the function using minion \n",
    "dimension = 5 #set dimension of the problem\n",
    "maxevals = 1000 #number of function calls\n",
    "x0 = [[0.0]*dimension] # initial guesses\n",
    "\n",
    "min = mpy.Minimizer(func=objective_function, x0=x0, bounds=[(-1, 1)]*dimension, algo=\"ARRDE\", relTol=0.0, \n",
    "                    maxevals=10000, callback=None, seed=None, options={\"minimum_population_size\":4})\n",
    "result = min.optimize()\n",
    "print(\"The minimum of the function is \", \"\\n\\t x : \", result.x, \"\\n\\t f(x) : \", result.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Basic Test Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minionpy provides a variety of test functions for evaluating optimization algorithms. The dictionary `testFunctionDict` below contains some of the fundamental functions available. Many of these functions have a global minimum at the origin, which can be problematic since some algorithms naturally converge toward it. To address this issue, CEC benchmark functions apply rotation and shifting to these basic functions, making them more representative of real-world optimization scenarios.  \n",
    "\n",
    "The test functions in `minionpy.test_functions` are vectorized by default. They accept input as a 2D NumPy array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testFunctionDict = {\n",
    "    \"sphere\" : mpytest.sphere, \n",
    "    \"rosenbrock\" : mpytest.rosenbrock, \n",
    "    \"rastrigin\" : mpytest.rastrigin, \n",
    "    \"schaffer2\" : mpytest.schaffer2, \n",
    "    \"griewank\" : mpytest.griewank, \n",
    "    \"ackley\" : mpytest.ackley, \n",
    "    \"zakharov\" : mpytest.zakharov, \n",
    "    \"bent_cigar\" : mpytest.bent_cigar, \n",
    "    \"levy\" : mpytest.levy, \n",
    "    \"discus\" : mpytest.discus, \n",
    "    \"drop_wave\" : mpytest.drop_wave, \n",
    "    \"goldstein_price\" : mpytest.goldstein_price, \n",
    "    \"exponential\" : mpytest.exponential,\n",
    "    \"quartic\" : mpytest.quartic, \n",
    "    \"hybrid_composition1\" : mpytest.hybrid_composition1,\n",
    "    \"hybrid_composition2\" : mpytest.hybrid_composition2,\n",
    "    \"hybrid_composition3\" : mpytest.hybrid_composition3,\n",
    "    \"happy_cat\"  : mpytest.happy_cat, \n",
    "    \"michalewics\" : mpytest.michalewicz,\n",
    "    \"scaffer6\" : mpytest.scaffer6, \n",
    "    \"hcf\" : mpytest.hcf, \n",
    "    \"grie_rosen\" : mpytest.grie_rosen,\n",
    "    \"dixon_price\" : mpytest.dixon_price, \n",
    "    \"eosom\" : mpytest.easom, \n",
    "    \"hgbat\" : mpytest.hgbat, \n",
    "    \"styblinski_tang\" : mpytest.styblinski_tang, \n",
    "    \"step\" : mpytest.step, \n",
    "    \"weierstrass\" : mpytest.weierstrass, \n",
    "    \"sum_squares\" : mpytest.sum_squares\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of different algorithms to minimize these functions can be compared as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 10\n",
    "maxevals = 10000\n",
    "np.random.seed(1)\n",
    "shift = 10 * np.random.rand(dimension)  # Shift randomly\n",
    "bounds = [(-10, 10)] * dimension\n",
    "x0 = [10 * np.random.rand(dimension)] # Initial guesses\n",
    "np.random.seed(None)\n",
    "\n",
    "for func_name in testFunctionDict:\n",
    "    #if func_name not in [\"schaffer2\", \"ackley\", \"rastrigin\", \"rosenbrock\"]:\n",
    "    #    continue  # Minimize only these functions; comment this line to compare all test functions\n",
    "\n",
    "    print(f\"Function: {func_name}\")\n",
    "\n",
    "    N = 0\n",
    "\n",
    "    def objective_function(X):\n",
    "        \"\"\"Shifted objective function for minimization.\"\"\"\n",
    "        global N\n",
    "        X = np.array(X) - shift  # Shift the space\n",
    "        N += len(X)\n",
    "        return testFunctionDict[func_name](X)\n",
    "\n",
    "    def objective_function_scipy(X):\n",
    "        \"\"\"Objective function for SciPy optimizers.\"\"\"\n",
    "        global N\n",
    "        N += 1\n",
    "        return testFunctionDict[func_name]([X])[0]\n",
    "\n",
    "    algoList = [\n",
    "        \"DE\", \"LSHADE\", \"JADE\", \"jSO\", \"j2020\", \"LSRTDE\", \"NLSHADE_RSP\",\n",
    "        \"ARRDE\", \"GWO_DE\", \"ABC\", \"NelderMead\", \"DA\", \"L_BFGS_B\"\n",
    "    ]\n",
    "    \n",
    "\n",
    "    for algo in algoList:\n",
    "        t_start = time.time()\n",
    "        N = 0\n",
    "        result = mpy.Minimizer(\n",
    "            func=objective_function, x0=x0, bounds=bounds, algo=algo, \n",
    "            relTol=0.0, maxevals=maxevals, callback=None, seed=None,\n",
    "            options={\"population_size\": 2*dimension}\n",
    "        ).optimize()\n",
    "        elapsed_time = time.time() - t_start\n",
    "        print(f\"\\tAlgorithm: {algo:<18} f(x): {result.fun:<15.8g} Elapsed: {elapsed_time:.3f} s\")\n",
    "\n",
    "    # Compare to SciPy algorithms\n",
    "    algorithms_scipy = [\n",
    "        (\"Scipy Nelder-Mead\", minimize, {\"x0\": x0[0], \"method\": \"Nelder-Mead\", \n",
    "                                         \"bounds\": bounds, \"options\": {\"maxfev\": maxevals, \"adaptive\": True}}),\n",
    "        (\"Scipy L-BFGS-B\", minimize, {\"x0\": x0[0], \"method\": \"L-BFGS-B\", \n",
    "                                      \"options\": {\"maxfun\": maxevals}, \"bounds\": bounds}),\n",
    "        (\"Scipy DA\", dual_annealing, {\"bounds\": bounds, \"maxfun\": maxevals, \"x0\": x0[0], \"no_local_search\": False})\n",
    "    ]\n",
    "\n",
    "    for name, func, kwargs in algorithms_scipy:\n",
    "        t_start = time.time()\n",
    "        N = 0\n",
    "        result = func(objective_function_scipy, **kwargs)\n",
    "        elapsed_time = time.time() - t_start\n",
    "        print(f\"\\tAlgorithm: {name:<18} f(x): {result.fun:<15.8g} Elapsed: {elapsed_time:.3f} s\")\n",
    "\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimizing Expensive Functions with Multithreading/Multiprocessing\n",
    "\n",
    "When the objective function is expensive to evaluate, multithreading can be used to speed up the calculation of the vectorized objective function. However, this requires that the objective function is **thread-safe**. \n",
    "\n",
    "If the objective function is not thread-safe, then **multiprocessing** can be used instead. This approach allows parallel execution across separate processes, which avoids the potential issues with thread safety.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example to vectorize a thread-safe function using multithreading and multiprocessing\n",
    "If the function is thread-safe to call cuncurrently, then we can safely use concurrent.futures.ThreadPoolExecutor (for multithreading) or concurrent.futures.ProcessPoolExecutor (for multiproceesing) directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to minimize (expensive to evaluate)\n",
    "def func(x):\n",
    "    ret = rosenbrock(x)\n",
    "    time.sleep(0.1)  # Simulate expensive computation\n",
    "    return ret\n",
    "\n",
    "# Parallel execution setup\n",
    "Nthreads = 8\n",
    "use_threads = True  # Toggle between ThreadPoolExecutor and ProcessPoolExecutor\n",
    "\n",
    "if use_threads:\n",
    "    executor = concurrent.futures.ThreadPoolExecutor(max_workers=Nthreads)\n",
    "else:\n",
    "    executor = concurrent.futures.ProcessPoolExecutor(max_workers=Nthreads)\n",
    "\n",
    "def objective_function(X):\n",
    "    return list(executor.map(func, X))  # Batch evaluation in parallel\n",
    "\n",
    "# Optimization problem settings\n",
    "dimension = 10\n",
    "maxevals = 1000\n",
    "x0 = [[3.0] * dimension]\n",
    "bounds = [(-10, 10)] * dimension\n",
    "\n",
    "# List of algorithms to test\n",
    "algorithms = {\n",
    "    \"ARRDE\": {\"options\": None},\n",
    "    \"L_BFGS_B\": {\"options\": {\"func_noise_ratio\": 0.0, \"N_points_derivative\": 1}},\n",
    "    \"DA\": {\"options\": None}\n",
    "}\n",
    "\n",
    "print(\"\\nOptimization Results:\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Run optimizations using Minion\n",
    "for algo, settings in algorithms.items():\n",
    "    start_time = time.time()\n",
    "    minimizer = mpy.Minimizer(\n",
    "        func=objective_function,\n",
    "        x0=x0,\n",
    "        bounds=bounds,\n",
    "        algo=algo,\n",
    "        relTol=0.0,\n",
    "        maxevals=maxevals,\n",
    "        callback=None,\n",
    "        seed=None,\n",
    "        options=settings[\"options\"]\n",
    "    )\n",
    "    result = minimizer.optimize()\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    print(f\"Algo : {algo:<30} | f(x) = {result.fun:<20.8g} | Elapsed: {elapsed:.2f} sec\")\n",
    "\n",
    "# Compare with SciPy optimizers (without multithreading)\n",
    "for algo, opt_func in [\n",
    "    (\"Scipy Dual Annealing\", dual_annealing),\n",
    "    (\"Scipy L-BFGS-B\", minimize)\n",
    "]:\n",
    "    start_time = time.time()\n",
    "    if algo == \"Scipy Dual Annealing\":\n",
    "        result = opt_func(func, bounds=bounds, maxfun=maxevals, no_local_search=False, x0=x0[0])\n",
    "    else:\n",
    "        result = opt_func(func, x0=x0[0], method=\"L-BFGS-B\", options={\"maxfun\": maxevals}, bounds=bounds)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Algo : {algo:<30} | f(x) = {result.fun:<20.8g} | Elapsed: {elapsed:.2f} sec\")\n",
    "\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Shutdown executor gracefully\n",
    "executor.shutdown()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithms implemented in Minion (ARRDE, L-BFGS-B, and Dual Annealing) significantly outperform their SciPy counterparts in speed. For example, Minion's Dual Annealing is roughly 4 times as fast as the SciPy's, while its L-BFGS-B is almost three times as fast. This performance improvement stems from Minion’s efficient numerical derivative computation, which batches function evaluations—an approach that greatly benefits minion's L-BFGS-B and Dual Annealing. Note that dual annealing use L-BFGS-B for local search.\n",
    "\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `minionpy.Thread_Parallel` to vectorize non-thread-safe member function\n",
    "\n",
    "In the previous example, we demonstrated how to minimize a thread-safe function. However, in real-world scenarios, the objective function is often a method of a class, and class methods are typically **not thread-safe**. In this example, we demonstrate how to minimize a **non-thread-safe function** using the `Thread_Parallel` class. This approach ensures proper parallelization even when the objective function modifies internal state, which can lead to race conditions in a multi-threaded environment.\n",
    "\n",
    "### 1. Define the Class with `objective_function`\n",
    "\n",
    "First, define a class that includes the `objective_function`. This function should accept a list of floats as input and return a single float as the output. In this example, the `objective_function` modifies an internal state, which makes it non-thread-safe. We will show how the minionpy `Thread_Parallel` class manages the parallel execution of such functions while ensuring thread isolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Objective : \n",
    "    \"\"\" \n",
    "    This illustrate a class with a non-thread-safe self.objective_function\n",
    "    \"\"\"\n",
    "    def __init__ (self, b) : \n",
    "        self.A=None  # There is a now class member that will be modified when self.objective_function is called.\n",
    "        self.b = b\n",
    "    \n",
    "    def update_A(self, x) : \n",
    "        self.A = self.b*np.sin(x) #modify self.A\n",
    "        time.sleep(0.05)  #simulate an expensive function\n",
    "\n",
    "    def objective_function(self, x) : \n",
    "        self.update_A(x)\n",
    "        ret = np.sum(self.A*x)  \n",
    "        #print(x, ret)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define the Thread_Parallel object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we vectorize `Objective.objective_function` using 8 threads, with the `b` parameter in the Objective class constructor set to `0.2`.\n",
    "t_parallel = mpy.Thread_Parallel(8, Objective, 0.2) \n",
    "\n",
    "#You can test the vectorization as follows : \n",
    "X = np.random.rand(8, 8) #randomly creates 6 vectors of dimension 8\n",
    "start = time.time()\n",
    "res = t_parallel(X) \n",
    "print(\"Vectorization using Thread_Parallel : \\n\\t\", res) \n",
    "print(\"Elapsed  : \", time.time()-start, \"\\n\")\n",
    "\n",
    "obj=Objective(b=0.2)\n",
    "start = time.time()\n",
    "res2 = [obj.objective_function(x) for x in X]\n",
    "print(\"Calling the function sequentially : \\n\\t\", res2) \n",
    "print(\"Elapsed  : \", time.time()-start, \"\\n\")\n",
    "\n",
    "#test if res and res2 are exactly the same \n",
    "print(np.array(res).all() == np.array(res2).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Minimize using one of minionpy algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 8 #set dimension of the problem\n",
    "maxevals = 1000 #number of function calls\n",
    "x0 = [[3.0]*dimension] # initial guess\n",
    "bounds = [(-10, 10)]*dimension\n",
    "algo = \"ARRDE\" \n",
    "\n",
    "now = time.time()\n",
    "min = mpy.Minimizer(func=t_parallel, x0=x0, bounds=bounds, algo=algo, relTol=0.0,\n",
    "                     maxevals=maxevals, callback=None, seed=None, options={\"population_size\": 0})\n",
    "result = min.optimize()\n",
    "elapsed= time.time()-now\n",
    "print(\"Algo : \",algo, \"\\n\\t x : \", result.x, \"\\n\\t f(x) : \", result.fun, \"\\n\\t Elapsed: \", elapsed, \" seconds\\n\")\n",
    "print(\"Test function value  : \", Objective(b=0.2).objective_function(np.asarray(result.x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the minimum found by the ARRDE algorithm corresponds to the correct function value. But what happens if we use ThreadPoolExecutor without considering the thread-safety of the objective_function method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = Objective(b=0.2)\n",
    "executor = concurrent.futures.ThreadPoolExecutor(max_workers=8)\n",
    "\n",
    "def vectorize_obj(X) : \n",
    "    ret = list(executor.map(obj.objective_function, np.asarray(X)))\n",
    "    return ret\n",
    "\n",
    "now = time.time()\n",
    "min = mpy.Minimizer(func=vectorize_obj, x0=x0, bounds=bounds, algo=algo, relTol=0.0, maxevals=maxevals, callback=None, seed=None, options=None)\n",
    "result = min.optimize()\n",
    "elapsed= time.time()-now\n",
    "print(\"Algo : \",algo, \"\\n\\t x : \", result.x, \"\\n\\t f(x) : \", result.fun, \"\\n\\t Elapsed: \", elapsed, \" seconds\\n\")\n",
    "print(\"Test function value  :\", obj.objective_function(np.asarray(result.x)))\n",
    "executor.shutdown(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the function value of the minimum is not the same as the actual function value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using multiprocessing for non-thread-safe functions using `minionpy.Process_Parallel`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If multiprocessing is preferred over multithreading—whether to bypass the Global Interpreter Lock (GIL) or to ensure clean separation of data during objective function vectorization—`minionpy` provides the `Process_Parallel` feature. It follows the same usage rules as `Thread_Parallel`. When using `Process_Parallel`, a predefined number of reusable processes are created, each with its own instance of the class object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_parallel = mpy.Process_Parallel(8, Objective, 0.2) \n",
    "\n",
    "#You can test the vectorization as follows : \n",
    "start = time.time()\n",
    "X = np.random.rand(8, 6) #randomly creates 6 vectors of dimension 8\n",
    "res = p_parallel(X) \n",
    "print(\"Vectorization using Process_Parallel : \\n\\t\", res) \n",
    "print(\"Elapsed  : \", time.time()-start, \"\\n\")\n",
    "\n",
    "obj=Objective(b=0.2)\n",
    "start = time.time()\n",
    "res2 = [obj.objective_function(x) for x in X]\n",
    "print(\"Calling the function sequentially : \\n\\t\", res2) \n",
    "print(\"Elapsed  : \", time.time()-start, \"\\n\")\n",
    "\n",
    "#test if res and res2 are exactly the same \n",
    "print(np.array(res).all() == np.array(res2).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 8 #set dimension of the problem\n",
    "maxevals = 1000 #number of function calls\n",
    "x0 = [[3.0]*dimension] # initial guess\n",
    "bounds = [(-10, 10)]*dimension\n",
    "algo = \"ARRDE\" \n",
    "\n",
    "now = time.time()\n",
    "min = mpy.Minimizer(func=p_parallel, x0=x0, bounds=bounds, algo=algo, relTol=0.0,\n",
    "                     maxevals=maxevals, callback=None, seed=None, options={\"population_size\": 0})\n",
    "result = min.optimize()\n",
    "elapsed= time.time()-now\n",
    "print(\"Algo : \",algo, \"\\n\\t x : \", result.x, \"\\n\\t f(x) : \", result.fun, \"\\n\\t Elapsed: \", elapsed, \" seconds\\n\")\n",
    "print(\"Test function value  : \", Objective(b=0.2).objective_function(np.asarray(result.x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Comparisons Using CEC Benchmark Problems\n",
    "\n",
    "We can compare the performance of different optimization algorithms by evaluating them on benchmark problems from the Congress on Evolutionary Computation (CEC) competition. The Minion library provides implementations of benchmark problems from the following CEC years: 2011, 2014, 2017, 2019, 2020, and 2022.\n",
    "\n",
    "- **CEC2014 and CEC2017**: These benchmarks contain 30 problems, implemented for dimensions 10, 20, 30, 50, and 100.\n",
    "- **CEC2019**: This set includes 10 problems with varying dimensions.\n",
    "- **CEC2020**: It contains 10 problems with dimensions 5, 10, 15, and 20.\n",
    "- **CEC2022**: This set consists of 12 problems with dimensions 10 and 20.\n",
    "\n",
    "CEC problems typically include a variety of function types:\n",
    "- **Basic functions** (e.g., Rosenbrock, Rastrigin),\n",
    "- **Hybrid functions** (new functions constructed by combining basic functions, where each component is evaluated using a different basic function),\n",
    "- **Composite functions** (linear combinations of basic functions, where the coefficients are also functions of the input vector).\n",
    "\n",
    "These functions are often shifted and rotated to introduce additional complexity.\n",
    "\n",
    "CEC2011 consists of a set of real-world problems, idealized and simplified for the competition. It contains 22 problems of varying dimensions. Note that, for CEC2011, MATLAB must be installed on the system. An example of how to minimize CEC2011 problems can be found in `examples/cec_11.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import concurrent.futures\n",
    "\n",
    "# This script minimizes CEC benchmark problems, repeated for NRuns times.\n",
    "\n",
    "# Global results variable\n",
    "results = []\n",
    "results_lock = threading.Lock()\n",
    "\n",
    "def test_optimization(func, bounds, dimension, func_name, Nmaxeval, seed):\n",
    "    \"\"\"Runs optimization algorithms on a given function and stores the results.\"\"\"\n",
    "    global results\n",
    "    result = {\n",
    "        \"Dimensions\": dimension,\n",
    "        \"Function\": func_name\n",
    "    }\n",
    "    \n",
    "    bounds_list = [bounds] * dimension\n",
    "    x0 = [[0.0 for _ in range(dimension)]]\n",
    "\n",
    "    print(f\"\\nRunning optimization for {func_name} (Dimension: {dimension})\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    for algo in algos:\n",
    "        res = mpy.Minimizer(\n",
    "            func, bounds_list, x0=x0, relTol=0.0, algo=algo, \n",
    "            maxevals=Nmaxeval, callback=None, seed=seed, \n",
    "            options={\n",
    "                \"population_size\"   : 0, #2*dimension, \n",
    "                \"func_noise_ratio\"  :  0.0, \n",
    "                \"N_points_derivative\": 1, \n",
    "                \"bound_strategy\" : \"none\"\n",
    "                }\n",
    "        ).optimize()\n",
    "        result[algo] = res.fun\n",
    "        print(f\"  {algo:<15} f(x): {res.fun:<20.8g}\")\n",
    "\n",
    "    def func_scipy(par):\n",
    "        return func([par])[0]\n",
    "    \n",
    "    # SciPy Optimizers\n",
    "    scipy_algorithms = [\n",
    "        (\"Scipy L-BFGS-B\", minimize, {\"x0\": x0[0], \"method\": \"L-BFGS-B\", \"options\": {\"maxfun\": Nmaxeval}, \"bounds\": bounds_list}),\n",
    "         (\"Scipy Nelder-Mead\", minimize, {\"x0\": x0[0], \"method\": \"Nelder-Mead\", \"bounds\": bounds_list, \"options\": {\"maxfev\": Nmaxeval, \"adaptive\": True}}),\n",
    "        (\"Scipy DA\", dual_annealing, {\"bounds\": bounds_list, \"maxfun\": Nmaxeval, \"no_local_search\": False, \"x0\": x0[0]}),\n",
    "    ]\n",
    "\n",
    "    for name, func_opt, kwargs in scipy_algorithms:\n",
    "        res = func_opt(func_scipy, **kwargs)\n",
    "        result[name] = res.fun\n",
    "        print(f\"  {name:<15} f(x): {res.fun:<20.8g}\")\n",
    "\n",
    "    with results_lock:\n",
    "        results.append(result)\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "def run_test_optimization(j, dim, year=2017, seed=None):\n",
    "    \"\"\"Runs the optimization for a specific function and CEC benchmark year.\"\"\"\n",
    "    cec_func_classes = {\n",
    "        2014: mpy.CEC2014Functions,\n",
    "        2017: mpy.CEC2017Functions,\n",
    "        2019: mpy.CEC2019Functions,\n",
    "        2020: mpy.CEC2020Functions,\n",
    "        2022: mpy.CEC2022Functions\n",
    "    }\n",
    "    \n",
    "    if year not in cec_func_classes:\n",
    "        raise Exception(\"Unknown CEC year.\")\n",
    "    \n",
    "    cec_func = cec_func_classes[year](function_number=j, dimension=dim)\n",
    "    test_optimization(cec_func, (-100, 100), dim, f\"func_{j}\", Nmaxeval, seed)\n",
    "\n",
    "# List of algorithms to be tested\n",
    "algos = [\n",
    "    \"LSHADE\", \"NLSHADE_RSP\", \"j2020\", \"jSO\", \"LSRTDE\", \"GWO_DE\", \"DE\",\n",
    "    \"JADE\", \"ARRDE\", \"ABC\", \"NelderMead\", \"DA\", \"L_BFGS_B\"\n",
    "]\n",
    "\n",
    "Nmaxeval = 100000  # Maximum number of function evaluations\n",
    "dimension = 20\n",
    "NRuns = 1  # Number of repetitions\n",
    "year = 2020  # CEC benchmark year\n",
    "\n",
    "# Function numbers for each CEC year\n",
    "func_numbers_dict = {\n",
    "    2022: list(range(1, 13)),\n",
    "    2020: list(range(1, 11)),\n",
    "    2019: list(range(1, 11)),\n",
    "    2017: list(range(1, 31)),\n",
    "    2014: list(range(1, 31)),\n",
    "}\n",
    "func_numbers = func_numbers_dict[year]\n",
    "\n",
    "# Run optimizations using multi-threading\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:\n",
    "    futures = [\n",
    "        executor.submit(run_test_optimization, j, dimension, year, k)\n",
    "        for k in range(NRuns)\n",
    "        for j in func_numbers\n",
    "    ]\n",
    "    concurrent.futures.wait(futures)\n",
    "    \n",
    "    for f in futures:\n",
    "        f.result()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of using minion/py in curve fitting problems\n",
    "\n",
    "\n",
    "Here, an example of using minion to minimize an objective function related to a curve fitting problem is demonstrated. \n",
    "The idea is first to define the data generation model, generate the data, fit the model, and report the result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Fitting Problems\n",
    "In this problem, we try fit a polynomial from a set of data. Specifically, a set of points ($\\{(x_i, y_i) \\mid i = 1, 2, \\dots, N\\}$) with $x \\in [0, 1]$ is generated according to:\n",
    "$$\n",
    "    f(x, a) = \\sum_{j=0}^{D-1} a_j x^j\n",
    "$$\n",
    "Given the coefficients $a_j$ that generate the data, the goal is to reproduce the data points by minimizing the objective function:\n",
    "$$\n",
    "    L = \\frac{1}{N}\\sum_{i=1}^N \\left(y_i - f(x_i, a)\\right)^2 \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Generate Data Points from a Polynomial\n",
    "dimension = 10  # Number of free parameters (polynomial degree is dimension - 1)\n",
    "np.random.seed(8)  # For reproducibility\n",
    "\n",
    "# True polynomial coefficients (random values)\n",
    "true_coefficients = [np.random.uniform(-1.0, 1.0) * (1.0 ** i) for i in range(dimension)]\n",
    "\n",
    "# Generate data points\n",
    "x_data = np.linspace(0.0, 1, dimension + 10)\n",
    "y_data = np.polyval(true_coefficients, x_data)\n",
    "\n",
    "# Step 2: Define the Polynomial Model\n",
    "def polynomial_model(x, coefficients):\n",
    "    \"\"\"Evaluate a polynomial at x given the coefficients.\"\"\"\n",
    "    return np.polyval(coefficients, x)\n",
    "\n",
    "# Step 3: Define the Objective Function\n",
    "def objective_function(coefficients):\n",
    "    \"\"\"Compute the mean squared error between the polynomial model and data points.\"\"\"\n",
    "    y_pred = polynomial_model(x_data, coefficients)\n",
    "    return np.mean((y_data - y_pred) ** 2)\n",
    "\n",
    "def objective_function_vect(X):\n",
    "    \"\"\"Vectorized version of the objective function for batch optimization.\"\"\"\n",
    "    return [objective_function(x) for x in X]\n",
    "\n",
    "# Optimization Settings\n",
    "bounds = [(-10, 10)] * dimension\n",
    "Nmaxeval = 20000\n",
    "algos = [\n",
    "    \"DE\", \"LSHADE\", \"JADE\", \"jSO\", \"j2020\", \"LSRTDE\", \"NLSHADE_RSP\",\n",
    "    \"ARRDE\", \"GWO_DE\", \"NelderMead\", \"ABC\", \"DA\", \"L_BFGS_B\"\n",
    "]\n",
    "\n",
    "# Step 4: Minimize the Objective Function and Plot Results\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(x_data, y_data, label=\"Data Points\", color=\"black\", marker=\"o\", zorder=3)\n",
    "\n",
    "x0 = [[0.0 for _ in range(dimension)]]\n",
    "\n",
    "print(\"\\nOptimization Results:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Run Optimization with Custom Algorithms\n",
    "for algo in algos:\n",
    "    res = mpy.Minimizer(\n",
    "        objective_function_vect, bounds, x0=x0, relTol=0.0,\n",
    "        algo=algo, maxevals=Nmaxeval, callback=None, seed=0,\n",
    "        options={\n",
    "            \"population_size\": 0, \n",
    "            \"func_noise_ratio\"  :  0.0, \n",
    "            \"N_points_derivative\": 1}\n",
    "    ).optimize()\n",
    "\n",
    "    print(f\"{algo:<30}: f(x) = {res.fun:<20.8g}\")\n",
    "    plt.plot(x_data, polynomial_model(x_data, res.x), label=algo, linewidth=1.2, alpha=0.7)\n",
    "\n",
    "# Run SciPy Optimizers\n",
    "scipy_algorithms = [\n",
    "    (\"Scipy Dual Annealing (DA)\", dual_annealing, {\"bounds\": bounds, \"maxfun\": Nmaxeval, \"no_local_search\": False, \"x0\": x0[0]}),\n",
    "    (\"Scipy L-BFGS-B\", minimize, {\"x0\": x0[0], \"bounds\": bounds, \"method\": \"L-BFGS-B\", \"options\": {\"maxfun\": Nmaxeval}}),\n",
    "    (\"Scipy Nelder-Mead\", minimize, {\"x0\": x0[0], \"bounds\": bounds, \"method\": \"Nelder-Mead\", \"options\": {\"maxfev\": Nmaxeval, \"adaptive\": True}}),\n",
    "]\n",
    "\n",
    "for name, func_opt, kwargs in scipy_algorithms:\n",
    "    res = func_opt(objective_function, **kwargs)\n",
    "    print(f\"{name:<30}: f(x) = {res.fun:<20.8g}\")\n",
    "    plt.plot(x_data, polynomial_model(x_data, res.x), label=name, linewidth=1.2, alpha=0.7)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Plot Formatting\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1), fontsize=9)\n",
    "plt.title(\"Polynomial Fit\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Mixture Model Fitting Problems\n",
    "\n",
    "Thsi time, the model is given by the sum of Gaussian functions:\n",
    "$$\n",
    "    f(x, a, b, c) = \\sum_{j=1}^{D/3} \\frac{a_j}{\\sum_{k=1}^{D/3} a_k} \\frac{1}{b_j \\sqrt{2\\pi}} \\exp\\left[-\\frac{1}{2} \\frac{(x-c_j)^2}{b_j^2}\\right]\n",
    "$$\n",
    "Here, $f(x, a, b, c)$ is normalized to represent a probability distribution. The data points are generated using predefined values of $a_j$, $b_j$, and $c_j$ within the interval $x \\in [-20, 20]$. The objective function is the same as in the case of polynomial fitting. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize, dual_annealing\n",
    "import concurrent.futures\n",
    "\n",
    "# Step 1: Generate Data Points from a Gaussian Mixture Model (GMM)\n",
    "np.random.seed(5)  # For reproducibility\n",
    "\n",
    "num_gauss = 5  # Number of Gaussians\n",
    "true_centers = 10 * (-1 + 2 * np.random.random(num_gauss))  # Random center positions\n",
    "true_widths = np.random.rand(num_gauss) + 1.0  # Widths (variances)\n",
    "true_coeffs = 2.0 * np.random.rand(num_gauss)  # Coefficients\n",
    "\n",
    "dimension = num_gauss * 3  # Total number of free parameters\n",
    "\n",
    "# Define a Gaussian function\n",
    "def gauss(x, center, width):\n",
    "    \"\"\"Compute a Gaussian value at x given center and width.\"\"\"\n",
    "    return (1.0 / (2.0 * np.pi * width ** 2)) * 0.5 * np.exp(-((x - center) ** 2) / (2 * width ** 2))\n",
    "\n",
    "# Define the Gaussian Mixture Model (GMM)\n",
    "def gmm(x, centers, widths, coeffs):\n",
    "    \"\"\"Evaluate the Gaussian Mixture Model (GMM) at x.\"\"\"\n",
    "    result = np.zeros_like(x)\n",
    "    coeffs = np.array(coeffs)\n",
    "    norm_coeff = coeffs / np.sum(coeffs)  # Normalize coefficients\n",
    "    for i in range(len(centers)):\n",
    "        result += norm_coeff[i] * gauss(x, centers[i], widths[i])\n",
    "    return result\n",
    "\n",
    "# Generate synthetic data\n",
    "x_data = np.linspace(-20, 20, dimension + 10)\n",
    "y_data = gmm(x_data, true_centers, true_widths, true_coeffs)\n",
    "\n",
    "# Step 2: Define the Model for Fitting\n",
    "def gmm_model(x, params):\n",
    "    \"\"\"Compute GMM model values for given parameters.\"\"\"\n",
    "    num_gauss = len(params) // 3\n",
    "    centers = params[:num_gauss]\n",
    "    widths = params[num_gauss:2*num_gauss]\n",
    "    coeffs = params[2*num_gauss:]\n",
    "    return gmm(x, centers, widths, coeffs)\n",
    "\n",
    "# Step 3: Define the Objective Function\n",
    "def objective_function(params):\n",
    "    \"\"\"Compute the mean squared error between model and data.\"\"\"\n",
    "    y_pred = gmm_model(x_data, params)\n",
    "    return np.mean((y_data - y_pred) ** 2)\n",
    "\n",
    "# Parallelized objective function\n",
    "executor = concurrent.futures.ThreadPoolExecutor(max_workers=8)\n",
    "\n",
    "def objective_function_vect(params):\n",
    "    \"\"\"Vectorized version of objective function using multithreading.\"\"\"\n",
    "    return list(executor.map(objective_function, params))\n",
    "\n",
    "# Optimization Settings\n",
    "bounds = [(-10, 10)] * dimension\n",
    "Nmaxeval = 10000\n",
    "algos = [\n",
    "    \"DE\", \"LSHADE\", \"JADE\", \"jSO\", \"LSRTDE\", \"NLSHADE_RSP\",\n",
    "    \"ARRDE\", \"GWO_DE\", \"NelderMead\", \"ABC\", \"DA\", \"L_BFGS_B\"\n",
    "]\n",
    "\n",
    "x0 = [[1.0 for _ in range(dimension)]]\n",
    "\n",
    "# Step 4: Minimize the Objective Function and Plot Results\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(x_data, y_data, label=\"Data\", color=\"black\", marker=\"o\", zorder=3)\n",
    "\n",
    "print(\"\\nOptimization Results:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Run Optimization with Custom Algorithms\n",
    "for algo in algos:\n",
    "    res = mpy.Minimizer(\n",
    "        objective_function_vect, bounds, x0=x0, relTol=0.0,\n",
    "        algo=algo, maxevals=Nmaxeval, callback=None, seed=None,\n",
    "        options={\"population_size\": 0}\n",
    "    ).optimize()\n",
    "\n",
    "    print(f\"{algo:<30}: f(x) = {res.fun:<20.8g}\")\n",
    "    plt.plot(x_data, gmm_model(x_data, res.x), label=algo, linewidth=1.2, alpha=0.7)\n",
    "\n",
    "# Run SciPy Optimizers\n",
    "scipy_algorithms = [\n",
    "    (\"Scipy L-BFGS-B\", minimize, {\"x0\": x0[0], \"bounds\": bounds, \"method\": \"L-BFGS-B\", \"options\": {\"maxfun\": Nmaxeval}}),\n",
    "    (\"Scipy Dual Annealing\", dual_annealing, {\"x0\": x0[0],\"bounds\": bounds, \"maxfun\": Nmaxeval, \"no_local_search\": False}),\n",
    "    (\"Scipy Nelder-Mead\", minimize, {\"x0\": x0[0], \"method\": \"Nelder-Mead\", \"options\": {\"maxfev\": Nmaxeval, \"adaptive\": True}}),\n",
    "]\n",
    "\n",
    "for name, func_opt, kwargs in scipy_algorithms:\n",
    "    res = func_opt(objective_function, **kwargs)\n",
    "    print(f\"{name:<30}: f(x) = {res.fun:<20.8g}\")\n",
    "    plt.plot(x_data, gmm_model(x_data, res.x), label=name, linewidth=1.2, alpha=0.7)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Plot Formatting\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1), fontsize=9)\n",
    "plt.title(\"Gaussian Mixture Model Fit\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.show()\n",
    "\n",
    "executor.shutdown()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More complex fitting problem: CT18 PDFs Fitting\n",
    "\n",
    "Here, we provide a slightly more challenging curve fitting problem. The task is to reproduce the CT18 parton distribution functions (PDFs) \\cite{Hou:2019efy}. The parameterization for valence up-quark ($u_v$), valence down-quark ($d_v$), gluon, anti-$u$ ($\\bar{u}$), anti-$d$ ($\\bar{d}$), and strange quark ($s$) PDFs at the initial scale is given by:\n",
    "$$\n",
    "    f_i(x) = a_0 x^{a_1-1} (1-x)^{a_2} P_i(y, a_3, a_4, \\dots), \\quad i \\in \\{u_v, d_v, g, \\bar{u}, \\bar{d}, s\\}\n",
    "$$\n",
    "Here, $P_i(y)$ is a Bernstein polynomial of degree 4, 3, or 5, depending on the specific PDF. The variable $y$ is defined as $y = \\sqrt{x}$ for $u_v$, $d_v$, and $g$, and as $y = (1 - (1 - \\sqrt{x}))^{a_3}$ for the sea quarks. The objective function is:\n",
    "$$\n",
    "    L = \\sum_i \\frac{1}{N} \\sum_{j=1}^N \\left(y_j - f_i(x_j)\\right)^2\n",
    "$$\n",
    "where $i \\in \\{u_v, d_v, g, \\bar{u}, \\bar{d}, s\\}$. The dimensionality of this problem is $D = 47$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CT18PDFs : \n",
    "    def __init__(self) : \n",
    "        self.parameters = {\n",
    "            \"uv_0\" : 3.385, \"uv_1\" : 0.763, \"uv_2\" : 3.036, \"uv_3\" : 1.502, \"uv_4\" : -0.147,\"uv_5\" : 1.671, \"uv_6\" : 0.,\n",
    "            \"dv_0\" : 0.490, \"dv_1\" : 0.763, \"dv_2\" : 3.036, \"dv_3\" : 2.615, \"dv_4\" : 1.828,\"dv_5\" : 2.721, \"dv_6\" : 0., \n",
    "            \"g_0\" : 2.690, \"g_1\" : 0.531, \"g_2\" : 3.148, \"g_3\" : 3.032, \"g_4\" : -1.705, \"g_5\" : 1.354, \n",
    "            \"ubar_0\" : 0.414, \"ubar_1\" : -0.022, \"ubar_2\" : 7.737, \"ubar_3\" : 4.0, \"ubar_4\" : 0.618,\"ubar_5\" : 0.195, \"ubar_6\" : 0.871, \"ubar_7\" : 0.267,\"ubar_8\" : 0.733,\n",
    "            \"dbar_0\" : 0.414, \"dbar_1\" : -0.022, \"dbar_2\" : 7.737, \"dbar_3\" : 4.0, \"dbar_4\" : 0.292,\"dbar_5\" : 0.647, \"dbar_6\" : 0.474, \"dbar_7\" : 0.741,\"dbar_8\" :1.0,\n",
    "            \"s_0\" : 0.288, \"s_1\" : -0.022, \"s_2\" : 10.31, \"s_3\" : 4.0, \"s_4\" : 0.466,\"s_5\" : 0.466, \"s_6\" : 0.225, \"s_7\" : 0.225,\"s_8\" : 1.0,\n",
    "        }\n",
    "        self.xlist = np.linspace(1e-3, 0.8, 50)\n",
    "        self.paramNames = list(self.parameters.keys())\n",
    "        self.originalData = self.getData()\n",
    "\n",
    "    def uv(self, x) : \n",
    "        a0 = self.parameters[\"uv_0\"]\n",
    "        a1 = self.parameters[\"uv_1\"]\n",
    "        a2 = self.parameters[\"uv_2\"]\n",
    "        a3 = self.parameters[\"uv_3\"]\n",
    "        a4 = self.parameters[\"uv_4\"]\n",
    "        a5 = self.parameters[\"uv_5\"]\n",
    "        a6 = self.parameters[\"uv_6\"]\n",
    "        y= np.sqrt(x)\n",
    "        P = np.sinh(a3)*(1-y)**4 + np.sinh(a4) *4*y*(1-y)**3 + np.sinh(a5) *6*y**2*(1-y)**2 + np.sinh(a6) *4*y**3*(1-y) + y**4\n",
    "        return a0 * x**(a1-1)*(1-x)**a2*P\n",
    "    \n",
    "    def dv(self, x) : \n",
    "        a0 = self.parameters[\"dv_0\"]\n",
    "        a1 = self.parameters[\"dv_1\"]\n",
    "        a2 = self.parameters[\"dv_2\"]\n",
    "        a3 = self.parameters[\"dv_3\"]\n",
    "        a4 = self.parameters[\"dv_4\"]\n",
    "        a5 = self.parameters[\"dv_5\"]\n",
    "        a6 = self.parameters[\"dv_6\"]\n",
    "        y= np.sqrt(x)\n",
    "        P = np.sinh(a3)*(1-y)**4 + np.sinh(a4) *4*y*(1-y)**3 + np.sinh(a5) *6*y**2*(1-y)**2 + np.sinh(a6) *4*y**3*(1-y) + y**4\n",
    "        return a0 * x**(a1-1)*(1-x)**a2*P\n",
    "    \n",
    "    def g(self, x) : \n",
    "        a0 = self.parameters[\"g_0\"]\n",
    "        a1 = self.parameters[\"g_1\"]\n",
    "        a2 = self.parameters[\"g_2\"]\n",
    "        a3 = self.parameters[\"g_3\"]\n",
    "        a4 = self.parameters[\"g_4\"]\n",
    "        a5 = self.parameters[\"g_5\"]\n",
    "        y= np.sqrt(x)\n",
    "        P = np.sinh(a3)*(1-y)**3 + np.sinh(a4) *3*y*(1-y)**2 + np.sinh(a5) *3*y**2*(1-y)  + y**3\n",
    "        return a0 * x**(a1-1)*(1-x)**a2*P\n",
    "    \n",
    "    def ubar(self, x) : \n",
    "        a0 = self.parameters[\"ubar_0\"]\n",
    "        a1 = self.parameters[\"ubar_1\"]\n",
    "        a2 = self.parameters[\"ubar_2\"]\n",
    "        a3 = self.parameters[\"ubar_3\"]\n",
    "        a4 = self.parameters[\"ubar_4\"]\n",
    "        a5 = self.parameters[\"ubar_5\"]\n",
    "        a6 = self.parameters[\"ubar_6\"]\n",
    "        a7 = self.parameters[\"ubar_7\"]\n",
    "        a8 = self.parameters[\"ubar_8\"]\n",
    "        y= 1-(1-np.sqrt(x))**a3\n",
    "        P = (1-y)**5 + a4 * 5*y*(1-y)**4 + a5 * 10*y**2*(1-y)**3 +  a6 * 10*y**3*(1-y)**2 +  a7 * 5*y**4*(1-y)+  a8 * 5*y**5\n",
    "        return a0 * x**(a1-1)*(1-x)**a2*P\n",
    "    \n",
    "    def dbar(self, x) : \n",
    "        a0 = self.parameters[\"dbar_0\"]\n",
    "        a1 = self.parameters[\"dbar_1\"]\n",
    "        a2 = self.parameters[\"dbar_2\"]\n",
    "        a3 = self.parameters[\"dbar_3\"]\n",
    "        a4 = self.parameters[\"dbar_4\"]\n",
    "        a5 = self.parameters[\"dbar_5\"]\n",
    "        a6 = self.parameters[\"dbar_6\"]\n",
    "        a7 = self.parameters[\"dbar_7\"]\n",
    "        a8 = self.parameters[\"dbar_8\"]\n",
    "        y= 1-(1-np.sqrt(x))**a3\n",
    "        P = (1-y)**5 + a4 * 5*y*(1-y)**4 + a5 * 10*y**2*(1-y)**3 +  a6 * 10*y**3*(1-y)**2 +  a7 * 5*y**4*(1-y)+  a8 * 5*y**5\n",
    "        return a0 * x**(a1-1)*(1-x)**a2*P\n",
    "    \n",
    "    def s(self, x) : \n",
    "        a0 = self.parameters[\"s_0\"]\n",
    "        a1 = self.parameters[\"s_1\"]\n",
    "        a2 = self.parameters[\"s_2\"]\n",
    "        a3 = self.parameters[\"s_3\"]\n",
    "        a4 = self.parameters[\"s_4\"]\n",
    "        a5 = self.parameters[\"s_5\"]\n",
    "        a6 = self.parameters[\"s_6\"]\n",
    "        a7 = self.parameters[\"s_7\"]\n",
    "        a8 = self.parameters[\"s_8\"]\n",
    "        y= 1-(1-np.sqrt(x))**a3\n",
    "        P = (1-y)**5 + a4 * 5*y*(1-y)**4 + a5 * 10*y**2*(1-y)**3 +  a6 * 10*y**3*(1-y)**2 +  a7 * 5*y**4*(1-y)+  a8 * 5*y**5\n",
    "        return a0 * x**(a1-1)*(1-x)**a2*P\n",
    "    \n",
    "    def u(self, x) : return self.uv(x)+self.ubar(x)\n",
    "    def d(self, x) : return self.dv(x)+self.dbar(x) \n",
    "\n",
    "    def setParameter(self, pars) : \n",
    "        assert(len(pars)==len(self.parameters)) \n",
    "        self.parameters= dict(zip(self.paramNames, pars))\n",
    "\n",
    "    def getData(self) : \n",
    "        x= self.xlist\n",
    "        return [ x*self.u(self.xlist), x*self.ubar(self.xlist), x*self.d(self.xlist), x*self.dbar(self.xlist), x*self.g(self.xlist), x*self.s(self.xlist)]\n",
    "    \n",
    "    def objective_function(self, params): \n",
    "        self.setParameter(params) \n",
    "        data = self.getData() \n",
    "        ret =0\n",
    "        for do, d in zip(self.originalData, data) : \n",
    "            ret = ret + np.sum((do-d)**2)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct18 = CT18PDFs()\n",
    "data = ct18.getData()\n",
    "# Create a 3x2 grid of subplots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(10, 5))\n",
    "\n",
    "# List of labels for each plot\n",
    "labels = [\"u\", \"ubar\", \"d\", \"dbar\", \"g\", \"s\"]\n",
    "\n",
    "# Plotting each function in its corresponding subplot\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.plot(ct18.xlist, data[i], label=labels[i])\n",
    "    ax.set_xlim(0.1, 0.8)\n",
    "    ax.set_xlabel(\"x\")\n",
    "    if (i%3 == 0):\n",
    "        ax.set_ylabel(r\"$xf(x)$\")\n",
    "    ax.legend()\n",
    "plt.subplots_adjust(hspace=0.15, wspace=0.17)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define Problem Dimensions and Settings\n",
    "dimension = 47\n",
    "print(\"Dimension:\", dimension)\n",
    "\n",
    "bounds = [(-10, 10)] * dimension\n",
    "Nmaxeval = 100000\n",
    "x0 = [[1.0] * dimension]  # Initial guess\n",
    "\n",
    "# Step 2: Set Up Parallel Execution for CT18PDFs\n",
    "t_parallel = mpy.Thread_Parallel(4, CT18PDFs)  # Vectorize using 4 threads\n",
    "\n",
    "# Step 3: Define Optimization Algorithms\n",
    "algos = [\n",
    "    \"DE\", \"LSHADE\", \"JADE\", \"jSO\", \"j2020\", \"LSRTDE\", \"NLSHADE_RSP\",\n",
    "    \"ARRDE\", \"GWO_DE\", \"NelderMead\", \"ABC\", \"DA\", \"L_BFGS_B\"\n",
    "]\n",
    "\n",
    "# Step 4: Run Optimization and Collect Results\n",
    "results = {}\n",
    "\n",
    "print(\"\\nOptimization Results:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for algo in algos:\n",
    "    res = mpy.Minimizer(\n",
    "        t_parallel, bounds, x0=x0, algo=algo, relTol=0.0,\n",
    "        maxevals=Nmaxeval, callback=None, seed=None,\n",
    "        options={\n",
    "            \"population_size\": 150,\n",
    "            \"func_noise_ratio\"  :  0.0, \n",
    "            \"N_points_derivative\": 1\n",
    "        }\n",
    "    ).optimize()\n",
    "\n",
    "    print(f\"{algo:<30}: f(x) = {res.fun:<20.8g}\")\n",
    "    results[algo] = res\n",
    "\n",
    "# Step 5: Run SciPy Optimizers\n",
    "scipy_algorithms = [\n",
    "    (\"Scipy L-BFGS-B\", minimize, {\"x0\": x0[0], \"bounds\": bounds, \"method\": \"L-BFGS-B\", \"options\": {\"maxfun\": Nmaxeval}}),\n",
    "    (\"Scipy Dual Annealing\", dual_annealing, {\"x0\": x0[0],\"bounds\": bounds, \"maxfun\": Nmaxeval, \"no_local_search\": False}),\n",
    "]\n",
    "\n",
    "for name, func_opt, kwargs in scipy_algorithms:\n",
    "    res = func_opt(ct18.objective_function, **kwargs)\n",
    "    print(f\"{name:<30}: f(x) = {res.fun:<20.8g}\")\n",
    "    results[name] = res\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Step 6: Plot Results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 6))\n",
    "labels = [\"u-data\", \"ubar-data\", \"d-data\", \"dbar-data\", \"g-data\", \"s-data\"]\n",
    "\n",
    "# Plot each dataset in its corresponding subplot\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.plot(ct18.xlist, data[i], label=labels[i], color=\"black\", linestyle=\"dotted\", linewidth=1.2)\n",
    "\n",
    "    # Overlay model predictions for selected algorithms\n",
    "    for algo in [\"ARRDE\", \"DA\", \"Scipy Dual Annealing\", \"L_BFGS_B\"]:\n",
    "        ct18.setParameter(results[algo].x)\n",
    "        theo = ct18.getData()\n",
    "        ax.plot(ct18.xlist, theo[i], label=algo, linewidth=1.2, alpha=0.8)\n",
    "\n",
    "    ax.set_xlim(0.1, 0.8)\n",
    "    ax.set_xlabel(\"x\")\n",
    "    if i % 3 == 0:\n",
    "        ax.set_ylabel(r\"$xf(x)$\")\n",
    "    ax.legend(fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
